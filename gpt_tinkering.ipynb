{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sdtDsu1Y0EqL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(69)\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANr5dn7W0EqR",
        "outputId": "a00cbe8d-e1c6-454b-b552-4ffd17ce17e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset in characters:  493412\n"
          ]
        }
      ],
      "source": [
        "with open('data/kon.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "print(\"length of dataset in characters: \", len(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pANiObIZ0EqU",
        "outputId": "98f70469-1c89-4341-89e8-c142a14331b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ui:\n",
            "Sis, come on. You'd better get out of bed. Sis?\n",
            "\n",
            "Yui:\n",
            "Ah! I-it's eight! I'm late! Oh!\n",
            "\n",
            "Ui:\n",
            "Hey, why the rush? Hm?\n",
            "\n",
            "Yui:\n",
            "See you later!\n",
            "\n",
            "Lady:\n",
            "Oh, good morning, Yui.\n",
            "\n",
            "Yui:\n",
            "Good morning!\n",
            "\n",
            "Yui:\n",
            "What?! I read the clock wrong!\n",
            "Starting today, I'm a high schooler!\n",
            "\n",
            "Opening Song\n",
            "Cagayake!GIRLS by 放課後ティータイム(After School Tea Time)\n",
            "\n",
            "Girls:\n",
            "Congratulations on starting school here!\n",
            "\n",
            "Girl 1:\n",
            "Please join the Tennis Club!\n",
            "\n",
            "Girl 2:\n",
            "The Judo Club's better!\n",
            "\n",
            "Girl 3:\n",
            "Please join the Tea Ceremony Club!\n",
            "\n",
            "Girl 4:\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WvM5h6_i3KsM"
      },
      "outputs": [],
      "source": [
        "# remove japanese characters\n",
        "text = ''.join(filter(lambda character:ord(character) < 0x3000, text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7SOcWJM0EqW",
        "outputId": "a82a4da8-a8ed-47bf-cfb5-2e4c59dee2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique characters: 93 \n",
            " !\"#$%&'(),-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz{|}~°éū‘’…♪\n"
          ]
        }
      ],
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"unique characters:\", vocab_size, ''.join(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yobmmaeK0EqX",
        "outputId": "26669f38-4b26-4b53-f642-ee7543e7c578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, 'A': 28, 'B': 29, 'C': 30, 'D': 31, 'E': 32, 'F': 33, 'G': 34, 'H': 35, 'I': 36, 'J': 37, 'K': 38, 'L': 39, 'M': 40, 'N': 41, 'O': 42, 'P': 43, 'Q': 44, 'R': 45, 'S': 46, 'T': 47, 'U': 48, 'V': 49, 'W': 50, 'X': 51, 'Y': 52, 'Z': 53, '[': 54, ']': 55, 'a': 56, 'b': 57, 'c': 58, 'd': 59, 'e': 60, 'f': 61, 'g': 62, 'h': 63, 'i': 64, 'j': 65, 'k': 66, 'l': 67, 'm': 68, 'n': 69, 'o': 70, 'p': 71, 'q': 72, 'r': 73, 's': 74, 't': 75, 'u': 76, 'v': 77, 'w': 78, 'x': 79, 'y': 80, 'z': 81, '{': 82, '|': 83, '}': 84, '~': 85, '°': 86, 'é': 87, 'ū': 88, '‘': 89, '’': 90, '…': 91, '♪': 92, '': 93}\n",
            "{0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '#', 5: '$', 6: '%', 7: '&', 8: \"'\", 9: '(', 10: ')', 11: ',', 12: '-', 13: '.', 14: '/', 15: '0', 16: '1', 17: '2', 18: '3', 19: '4', 20: '5', 21: '6', 22: '7', 23: '8', 24: '9', 25: ':', 26: ';', 27: '?', 28: 'A', 29: 'B', 30: 'C', 31: 'D', 32: 'E', 33: 'F', 34: 'G', 35: 'H', 36: 'I', 37: 'J', 38: 'K', 39: 'L', 40: 'M', 41: 'N', 42: 'O', 43: 'P', 44: 'Q', 45: 'R', 46: 'S', 47: 'T', 48: 'U', 49: 'V', 50: 'W', 51: 'X', 52: 'Y', 53: 'Z', 54: '[', 55: ']', 56: 'a', 57: 'b', 58: 'c', 59: 'd', 60: 'e', 61: 'f', 62: 'g', 63: 'h', 64: 'i', 65: 'j', 66: 'k', 67: 'l', 68: 'm', 69: 'n', 70: 'o', 71: 'p', 72: 'q', 73: 'r', 74: 's', 75: 't', 76: 'u', 77: 'v', 78: 'w', 79: 'x', 80: 'y', 81: 'z', 82: '{', 83: '|', 84: '}', 85: '~', 86: '°', 87: 'é', 88: 'ū', 89: '‘', 90: '’', 91: '…', 92: '♪', 93: ''}\n",
            "encoded: [48, 64, 25, 0, 46, 64, 74, 11, 1, 58, 70, 68, 60, 1, 70, 69, 13, 1, 52, 70]\n",
            "decoded: Ui:\n",
            "Sis, come on. Yo\n",
            "vocab size: 94\n"
          ]
        }
      ],
      "source": [
        "# Very simple tokenizer\n",
        "stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "itos = {i:ch for i,ch in enumerate(chars)}\n",
        "# add special token for padding\n",
        "stoi[''] = len(stoi)\n",
        "itos[len(itos)] = ''\n",
        "print(stoi)\n",
        "print(itos)\n",
        "encode = lambda s: [stoi[ch] for ch in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "print(\"encoded:\", encode(text[:20]))\n",
        "print(\"decoded:\", decode(encode(text[:20])))\n",
        "vocab_size = len(itos)\n",
        "print(\"vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pnf9KfP0EqY",
        "outputId": "ff581168-335a-4f0f-efeb-0d4bd5b225ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([493171])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.int64)\n",
        "data.to(device)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ2fY1pR0EqY",
        "outputId": "5eb599e0-fb79-4cdb-c4b9-52a781d67151"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1, 58, 70, 68, 60,  1, 70, 69, 13,  1,\n",
              "        52, 70, 76,  8, 59,  1, 57, 60, 75, 75, 60, 73,  1, 62, 60, 75,  1, 70,\n",
              "        76, 75,  1, 70, 61,  1, 57, 60, 59, 13,  1, 46, 64, 74, 27,  0,  0, 52,\n",
              "        76, 64, 25,  0, 28, 63,  2,  1, 36, 12, 64, 75,  8, 74,  1, 60, 64, 62,\n",
              "        63, 75,  2,  1, 36,  8, 68,  1, 67, 56, 75, 60,  2,  1, 42, 63,  2,  0,\n",
              "         0, 48, 64, 25,  0, 35, 60, 80, 11,  1])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIaYesPh0Eqa",
        "outputId": "caa27cbb-5ae3-4406-8194-646264d4ba99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([468512]) torch.Size([24659])\n"
          ]
        }
      ],
      "source": [
        "n = int(len(data) * 0.95)\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(train_data.shape, val_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bFhizcI0Eqa",
        "outputId": "c93a4d43-6fb2-4de7-aefc-8fed47e4a861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([48, 64, 25,  0, 46, 64, 74, 11,  1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VHHMHja0Eqb",
        "outputId": "6a88e780-075f-4c14-e198-9c14d6ae4044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "context: [48] target: 64\n",
            "context: [48, 64] target: 25\n",
            "context: [48, 64, 25] target: 0\n",
            "context: [48, 64, 25, 0] target: 46\n",
            "context: [48, 64, 25, 0, 46] target: 64\n",
            "context: [48, 64, 25, 0, 46, 64] target: 74\n",
            "context: [48, 64, 25, 0, 46, 64, 74] target: 11\n",
            "context: [48, 64, 25, 0, 46, 64, 74, 11] target: 1\n"
          ]
        }
      ],
      "source": [
        "# context and target simulation\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1].tolist()\n",
        "    target = y[t].item()\n",
        "    print('context:', context, 'target:', target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skFCPvQC0Eqc",
        "outputId": "08990c5b-88af-4a51-ce37-3c59989d6d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "inputs:\n",
            "torch.Size([4, 128])\n",
            "tensor([[66, 70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1,\n",
            "         64, 74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0,\n",
            "         41, 70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1,\n",
            "         74, 63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75,\n",
            "         75, 64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1,\n",
            "         60, 77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70,\n",
            "         25,  0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,\n",
            "          9, 36],\n",
            "        [70, 75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60,\n",
            "         13, 13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,\n",
            "          8, 74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1,\n",
            "         64, 75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13,\n",
            "         13,  1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0,\n",
            "         52, 76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71,\n",
            "         67, 56],\n",
            "        [ 1, 73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1,\n",
            "         74, 67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48,\n",
            "         64, 25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0,\n",
            "         40, 64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0,\n",
            "         35, 76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63,\n",
            "         75,  1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78,\n",
            "         64, 75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1,\n",
            "         75, 63],\n",
            "        [59, 56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63,\n",
            "         56, 75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47,\n",
            "         74, 76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,\n",
            "          8, 74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,\n",
            "          0, 28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63,\n",
            "         60,  1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60,\n",
            "         13,  0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78,\n",
            "         63, 56]], device='cuda:0')\n",
            "targets:\n",
            "torch.Size([4, 128])\n",
            "tensor([[70, 25,  0, 40, 64, 74, 74,  1, 52, 56, 68, 56, 69, 56, 66, 56,  1, 64,\n",
            "         74,  1, 73, 60, 56, 67, 67, 80,  1, 62, 73, 60, 56, 75,  2,  0,  0, 41,\n",
            "         70, 57, 76, 80, 70, 25,  0, 36, 75,  8, 74,  1, 67, 64, 66, 60,  1, 74,\n",
            "         63, 60,  8, 74,  1, 62, 60, 75, 75, 64, 69, 62,  1, 71, 73, 60, 75, 75,\n",
            "         64, 60, 73,  1, 56, 69, 59,  1, 71, 73, 60, 75, 75, 64, 60, 73,  1, 60,\n",
            "         77, 60, 73, 80,  1, 59, 56, 80,  2,  0,  0, 46, 56, 78, 56, 66, 70, 25,\n",
            "          0, 54, 62, 64, 62, 62, 67, 60, 74, 55,  0,  0, 40, 64, 70, 25,  0,  9,\n",
            "         36,  1],\n",
            "        [75,  0,  0, 40, 64, 70, 25,  0, 39, 60, 75,  8, 74,  1, 74, 60, 60, 13,\n",
            "         13, 13,  0,  0, 45, 64, 75, 74, 76, 25,  0, 48, 63, 11,  1, 64, 75,  8,\n",
            "         74,  1, 69, 70, 75, 63, 64, 69, 62,  2,  0, 30, 63, 60, 58, 66,  1, 64,\n",
            "         75,  2,  0, 40, 70, 76, 74, 75, 56, 58, 63, 60,  2,  0,  0, 47, 74, 76,\n",
            "         68, 76, 62, 64, 25,  0, 36,  1, 63, 56, 77, 60,  1, 75, 70, 13, 13, 13,\n",
            "          1, 57, 70, 78,  1, 70, 76, 75,  1, 75, 70, 59, 56, 80, 13,  0,  0, 52,\n",
            "         76, 64, 25,  0, 31, 70,  1, 80, 70, 76,  1, 63, 56, 77, 60,  1, 71, 67,\n",
            "         56, 69],\n",
            "        [73, 76, 69, 13, 13,  1, 56,  1, 67, 64, 75, 75, 67, 60, 13, 13,  1, 74,\n",
            "         67, 70, 78, 60, 73,  1, 71, 67, 60, 56, 74, 60, 13, 13,  0,  0, 48, 64,\n",
            "         25,  0, 46, 70, 73, 73, 80, 13,  0,  0, 28, 81, 76, 74, 56, 25,  0, 40,\n",
            "         64, 70, 12, 74, 60, 68, 71, 56, 64, 13,  0,  0, 37, 76, 69, 25,  0, 35,\n",
            "         76, 63, 27,  0,  0, 48, 64, 25,  0, 36,  1, 75, 63, 70, 76, 62, 63, 75,\n",
            "          1, 80, 70, 76,  8, 73, 60,  1, 73, 76, 69, 69, 64, 69, 62,  1, 78, 64,\n",
            "         75, 63,  1, 68, 80,  1, 74, 64, 74, 75, 60, 73,  1, 56, 69, 59,  1, 75,\n",
            "         63, 60],\n",
            "        [56, 80, 27,  0,  0, 45, 64, 75, 74, 76, 25,  0, 46, 70,  1, 78, 63, 56,\n",
            "         75,  1, 64, 61,  1, 64, 75,  1, 64, 74, 69,  8, 75, 27,  0,  0, 47, 74,\n",
            "         76, 68, 76, 62, 64, 25,  0, 30,  8, 68, 70, 69, 11,  1, 67, 60, 75,  8,\n",
            "         74,  1, 75, 73, 80,  1, 64, 75,  2,  0,  0, 45, 64, 75, 74, 76, 25,  0,\n",
            "         28, 63,  2,  1, 50, 60, 67, 67, 11,  1, 59, 70, 78, 69,  1, 75, 63, 60,\n",
            "          1, 63, 56, 75, 58, 63, 11,  1, 36,  1, 74, 76, 71, 71, 70, 74, 60, 13,\n",
            "          0,  0, 47, 74, 76, 68, 76, 62, 64, 25,  0, 33, 73, 70, 68,  1, 78, 63,\n",
            "         56, 75]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(69)\n",
        "batch_size = 4 # number of parallel blocks\n",
        "block_size = 8 # number of characters in each block = context length\n",
        "\n",
        "def get_batch(split, block_size):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train', 128)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZUYR7UC0Eqe",
        "outputId": "68284d87-c596-46d2-b344-2a75d306235f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([512, 94])\n",
            "tensor(4.8468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "\n",
            "T!Ye?}Mrj~Bqpe’T.j3|KfdM-TiT]1kééé\"RrnbU)]UGi\n",
            "n]1PsnI'V%KL???p$:;’z/777mūQVwgk[bzh9i?}a 9tkM6d°5w\n"
          ]
        }
      ],
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        # Bigram language model: single layer, single token prediction\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        logits = self.token_embedding_table(idx)  # (B,T,C), B: batch=4, T: sequence=8, C: vocab=147\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            # flatten the logits and targets for torch cross entropy\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # generate max_new_tokens new tokens given the initial context idx\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = BigramLanguageModel(vocab_size)\n",
        "m = model.to(device)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "# randomly generate 100 tokens from initial model weights and idx = 0 = \\n\n",
        "print(decode(m.generate(idx=torch.zeros(\n",
        "    (1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf1W0gCJ0Eqi",
        "outputId": "149b3a0e-ce3c-42e9-d02e-a77d57a116cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.4686262607574463\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jVyXqMZ0Eqj",
        "outputId": "2fdc81f8-5de0-40ed-afef-7ec89f467616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Mitreme whet mel Yu~!\n",
            "Muk iteaw, s pQDoothin rei:rs to. I t fte al9V#Mal heaselouin$ooris], t't'Do%Qd a:\n",
            "Rint[o w?\n",
            "\n",
            "Yui-cka aron $9WSariou:\n",
            "Sume!\n",
            "\n",
            "Weriney se wd, thep g yonand oukse a:-sFiEmed. ritan?\n",
            "\n",
            "\n",
            "Whith, s th, lig-D y or yser Sok ryombué[cu?\n",
            "omeF%RAnybjugui#88ury, thani1’'vk alaSawrk!|{ūQ°|arm\n"
          ]
        }
      ],
      "source": [
        "# generate 100 tokens from trained model weights and idx = 0 = \\n\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mW7SE2pj-muH"
      },
      "source": [
        "Lets try out lower dimensional embeddings + positional embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wRzgeS0z-i_A"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from \n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(T, device=device)) # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "        \n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIhvnIhaAbKC",
        "outputId": "cd1a69f4-192d-4b94-d9a6-bc4d9246caa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.347278594970703\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQzNB-QIBUOJ",
        "outputId": "6bcda34d-2bf7-49ab-a0d5-e5bec0441795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Righe jacuindwereyn. wir mamand!\n",
            "We.\n",
            "\n",
            "He yoo:\n",
            "Rig! w! t h thay ck uinp harereve'teo o:\n",
            "\n",
            "Mi:\n",
            "Ri:\n",
            "Rithay Hor mer sjus to Tha:\n",
            "Fe gof amese.\n",
            "Ri:\n",
            "Risherpllurs Le n'ty s whang ru Y w meng!\n",
            "He rivemuheveatst caf won.\n",
            "Alom?\n",
            "I t!\n",
            "\n",
            "Mid f ithe ate.\n",
            "\n",
            "Sheaugieng Yumuid Shere ayouh ngoit!\n",
            "Whead win on:\n",
            "Mund g \n"
          ]
        }
      ],
      "source": [
        "# generate\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=300)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mzedwSah988C"
      },
      "source": [
        "# Now for the Transformer Fundamentals!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MlxFojAr-Cor"
      },
      "source": [
        "## The mathematical trick to self-attention: triangular matrices for weighted averages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR0CbrSV0Eqk",
        "outputId": "81e17413-92c8-4199-d06e-82eb9cff3193"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]],\n",
            "\n",
            "        [[ 1.3488, -0.1396],\n",
            "         [ 0.2858,  0.9651],\n",
            "         [-2.0371,  0.4931],\n",
            "         [ 1.4870,  0.5910],\n",
            "         [ 0.1260, -1.5627],\n",
            "         [-1.1601, -0.3348],\n",
            "         [ 0.4478, -0.8016],\n",
            "         [ 1.5236,  2.5086]]])\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 2,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "print(x.shape)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltEwVCuxIegD",
        "outputId": "ff4ff464-1bee-4263-9fd7-b4fd620140a7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We want x[b,t] = mean_{i<=t} x[b,i] to very badly encode info of tokens before token t\n",
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)\n",
        "xbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyHfiV0OI2EY",
        "outputId": "5334dd5a-7014-441e-c4ed-f25161ed21e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
            "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
            "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# better way to do this: triangular matrix!\n",
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "print(wei)\n",
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "xbow2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBLSxfkAJD0A",
        "outputId": "add82619-0dc9-43e1-9fff-e1f48e45a767"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# even better: softmax for normalization of weights\n",
        "# version 3: use Softmax\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T,T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "xbow3 = wei @ x\n",
        "xbow3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvymyaOiJbbo",
        "outputId": "d2f3783f-74c2-45d0-91b0-ee05c9b59062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4700, 0.5300, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3140, 0.3170, 0.3690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2060, 0.2090, 0.2640, 0.3210, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1920, 0.1650, 0.2050, 0.2140, 0.2250, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1260, 0.1320, 0.0900, 0.0690, 0.2020, 0.3810, 0.0000, 0.0000],\n",
            "         [0.1440, 0.1500, 0.1540, 0.1630, 0.1220, 0.1160, 0.1500, 0.0000],\n",
            "         [0.0580, 0.0460, 0.0440, 0.0340, 0.1330, 0.1390, 0.0480, 0.4990]],\n",
            "\n",
            "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4970, 0.5030, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0040, 0.0540, 0.9430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.5030, 0.1000, 0.0140, 0.3840, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2570, 0.1220, 0.0820, 0.1950, 0.3440, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0330, 0.1210, 0.5640, 0.0410, 0.0430, 0.1990, 0.0000, 0.0000],\n",
            "         [0.2080, 0.0880, 0.0420, 0.1640, 0.2250, 0.0830, 0.1890, 0.0000],\n",
            "         [0.2230, 0.0870, 0.0160, 0.2280, 0.1030, 0.0330, 0.1210, 0.1890]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 5.4000e-02, -1.3900e-01, -1.7200e-01, -1.0700e-01,  3.0000e-03,\n",
            "          -9.0000e-03, -5.4000e-02,  2.1000e-02,  1.2100e-01, -6.7000e-02,\n",
            "          -4.0000e-02,  6.1000e-02, -3.1000e-02, -1.2000e-01,  1.1400e-01,\n",
            "          -1.8000e-02],\n",
            "         [-1.1800e-01, -1.2300e-01, -2.7100e-01, -2.2000e-01, -1.4000e-02,\n",
            "           2.7900e-01,  1.9300e-01, -2.1100e-01,  2.9400e-01, -2.4800e-01,\n",
            "           3.0400e-01, -2.0300e-01,  2.1900e-01,  2.8000e-02,  2.5200e-01,\n",
            "          -2.3500e-01],\n",
            "         [ 1.6000e-02, -2.2000e-01, -3.2200e-01, -2.2200e-01, -2.0000e-03,\n",
            "           1.0700e-01,  1.6000e-02, -6.3000e-02,  2.7000e-01, -1.8500e-01,\n",
            "           8.0000e-02, -1.2000e-02,  5.5000e-02, -1.3300e-01,  2.4400e-01,\n",
            "          -1.2100e-01],\n",
            "         [ 1.2900e-01, -3.3800e-01, -4.2000e-01, -2.6100e-01,  6.0000e-03,\n",
            "          -1.6000e-02, -1.2700e-01,  4.8000e-02,  2.9700e-01, -1.6500e-01,\n",
            "          -9.1000e-02,  1.4300e-01, -7.1000e-02, -2.8900e-01,  2.7900e-01,\n",
            "          -4.9000e-02],\n",
            "         [ 1.5800e-01, -2.0200e-01, -1.9300e-01, -9.4000e-02,  1.2000e-02,\n",
            "          -1.5000e-01, -1.9400e-01,  1.4100e-01,  8.6000e-02, -6.0000e-03,\n",
            "          -2.2100e-01,  2.1100e-01, -1.6300e-01, -2.3800e-01,  9.2000e-02,\n",
            "           7.8000e-02],\n",
            "         [-1.3700e-01,  1.8700e-01,  1.8500e-01,  9.5000e-02, -1.0000e-02,\n",
            "           1.2200e-01,  1.6500e-01, -1.1700e-01, -9.1000e-02,  1.7000e-02,\n",
            "           1.8400e-01, -1.8000e-01,  1.3700e-01,  2.1200e-01, -9.4000e-02,\n",
            "          -5.9000e-02],\n",
            "         [ 3.9000e-02, -1.2400e-01, -1.6000e-01, -1.0200e-01,  2.0000e-03,\n",
            "           7.0000e-03, -3.5000e-02,  7.0000e-03,  1.1800e-01, -6.9000e-02,\n",
            "          -1.8000e-02,  4.0000e-02, -1.5000e-02, -1.0000e-01,  1.0900e-01,\n",
            "          -2.8000e-02],\n",
            "         [-6.8000e-02,  6.2800e-01,  9.0300e-01,  6.1500e-01,  5.0000e-03,\n",
            "          -2.6500e-01, -1.3000e-02,  1.4800e-01, -7.4500e-01,  5.0200e-01,\n",
            "          -1.8100e-01, -1.0000e-03, -1.2200e-01,  3.9900e-01, -6.7500e-01,\n",
            "           3.1500e-01]],\n",
            "\n",
            "        [[ 4.6400e-01, -8.9900e-01, -1.0320e+00, -6.0300e-01,  2.9000e-02,\n",
            "          -2.5300e-01, -5.1400e-01,  2.9500e-01,  6.5500e-01, -3.0200e-01,\n",
            "          -4.9100e-01,  5.6700e-01, -3.7000e-01, -8.6600e-01,  6.3200e-01,\n",
            "           3.0000e-02],\n",
            "         [ 3.5800e-01, -3.6000e-01, -2.9100e-01, -1.1100e-01,  2.9000e-02,\n",
            "          -3.9800e-01, -4.5500e-01,  3.5600e-01,  6.9000e-02,  7.5000e-02,\n",
            "          -5.4800e-01,  4.9200e-01, -4.0300e-01, -4.8500e-01,  9.6000e-02,\n",
            "           2.3800e-01],\n",
            "         [-6.0400e-01,  1.3840e+00,  1.6660e+00,  1.0110e+00, -3.4000e-02,\n",
            "           1.9900e-01,  6.3200e-01, -3.0200e-01, -1.1310e+00,  5.8900e-01,\n",
            "           5.3200e-01, -7.0300e-01,  4.0700e-01,  1.2440e+00, -1.0730e+00,\n",
            "           9.8000e-02],\n",
            "         [ 4.9000e-01, -6.9000e-01, -6.9600e-01, -3.6200e-01,  3.5000e-02,\n",
            "          -4.2500e-01, -5.8800e-01,  4.1100e-01,  3.5200e-01, -7.9000e-02,\n",
            "          -6.5000e-01,  6.4100e-01, -4.8300e-01, -7.7200e-01,  3.6300e-01,\n",
            "           1.9900e-01],\n",
            "         [ 1.5100e-01, -4.5500e-01, -5.8200e-01, -3.6900e-01,  7.0000e-03,\n",
            "           1.6000e-02, -1.3900e-01,  3.4000e-02,  4.2500e-01, -2.4800e-01,\n",
            "          -7.8000e-02,  1.5800e-01, -6.3000e-02, -3.7100e-01,  3.9600e-01,\n",
            "          -9.5000e-02],\n",
            "         [-4.0100e-01,  8.8000e-01,  1.0470e+00,  6.3000e-01, -2.3000e-02,\n",
            "           1.5600e-01,  4.2600e-01, -2.1600e-01, -7.0000e-01,  3.5500e-01,\n",
            "           3.7300e-01, -4.7400e-01,  2.8400e-01,  8.0500e-01, -6.6600e-01,\n",
            "           4.0000e-02],\n",
            "         [ 1.1700e-01, -4.3200e-01, -5.7200e-01, -3.7000e-01,  4.0000e-03,\n",
            "           6.1000e-02, -9.4000e-02, -5.0000e-03,  4.3400e-01, -2.6500e-01,\n",
            "          -2.0000e-02,  1.0900e-01, -2.1000e-02, -3.3100e-01,  4.0000e-01,\n",
            "          -1.2400e-01],\n",
            "         [ 4.0400e-01, -4.5100e-01, -3.9500e-01, -1.7300e-01,  3.1000e-02,\n",
            "          -4.2200e-01, -5.0600e-01,  3.8500e-01,  1.3600e-01,  4.4000e-02,\n",
            "          -5.9600e-01,  5.4900e-01, -4.4000e-01, -5.7200e-01,  1.6000e-01,\n",
            "           2.4000e-01]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# finally: Query (what i look for), Key (What i am in this), \n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 16\n",
        "query = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False) # Linear layer C (embed) -> head size (16)\n",
        "\n",
        "q = query(x) # (B,T,16)\n",
        "k = key(x) # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1) # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "# print(wei.shape)\n",
        "# print(torch.round(torch.sum(wei, dim=1), decimals=3))\n",
        "# row_sum = wei.sum(dim=1)\n",
        "\n",
        "# # Compute the average sum\n",
        "# avg_sum = row_sum.mean()\n",
        "\n",
        "# # Filter out rows with sum lower than the average sum\n",
        "# wei = wei[:, row_sum >= avg_sum]\n",
        "# print(wei.shape)\n",
        "\n",
        "wei = wei * C**-0.5 # scaled attention as to not sharpen softmax\n",
        "\n",
        "# T = wei.shape[1]\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(torch.round(wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "out = wei @ v\n",
        "print(torch.round(out, decimals=3))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "z9UBFTl7RJz6"
      },
      "source": [
        "# Time to put attention in our last model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "29tuDoYfRInY"
      },
      "outputs": [],
      "source": [
        "class SelfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei * C**-0.5 # scaled attention\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yWMdfaSDSfqm"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # single head self-attention\n",
        "        self.sa_head = SelfAttentionHead(block_size, embed_size, embed_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply self-attention\n",
        "        x = self.sa_head(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLy8v6ipS-ih",
        "outputId": "9731dd14-63cb-471f-f2c4-312f5311906c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "2.3798604011535645\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedAttentionLanguageModel(vocab_size, 16, 32)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(5000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeF8Io5BTyvt",
        "outputId": "32fb8015-a9b6-41f7-f93d-d629ed98016d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Yuig vey.\n",
            "\n",
            "Oh, whel a wey Mou\n",
            "Miitng itnig ofunte ait oyo fon Lth!\n",
            "\n",
            "G mo youd tha:\n",
            "Yucl a uI's forst foo:\n",
            "Ritsu:\n",
            "Whe igigre I's?\n",
            "\n",
            "Mu:\n",
            "An toum sure!?\n",
            "\n",
            "Yui:\n",
            "Heery Tared soum p or qusmo, oe cunte's se n'ts yopean to'vetar the, dlorem, or toeah! Mon, Yuib:\n",
            "We hisugoured yo plle youe sus tere fur mecro:\n",
            "Work yo. than oo whorto lt lugaik ng my gar.. u&!\n",
            "\n",
            "Rito, todo.\n",
            "\n",
            "Mormetady! w bo,, oum Huka:\n",
            "Ohathe sourncerero:\n",
            "Ha-hem s-s'carit min!\n",
            "\n",
            "Mio:\n",
            "Thas albe ye'rret wereed too on pea rnhitat con ith hige'll\n"
          ]
        }
      ],
      "source": [
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.zeros((1, 1), dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SkREJPLwVCo3"
      },
      "source": [
        "# More heads! Multi-Head Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2Rgkap80VCLY"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([SelfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r9RFKTHiVlJh"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ohtB_CWstI",
        "outputId": "94ee0176-a814-4ce4-91e0-a977275f47f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0\n",
            "learning step: 500\n",
            "learning step: 1000\n",
            "learning step: 1500\n",
            "learning step: 2000\n",
            "learning step: 2500\n",
            "learning step: 3000\n",
            "learning step: 3500\n",
            "learning step: 4000\n",
            "learning step: 4500\n",
            "learning step: 5000\n",
            "learning step: 5500\n",
            "learning step: 6000\n",
            "learning step: 6500\n",
            "learning step: 7000\n",
            "learning step: 7500\n",
            "learning step: 8000\n",
            "learning step: 8500\n",
            "learning step: 9000\n",
            "learning step: 9500\n",
            "1.920032024383545\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps)\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ptYRjZW5Id",
        "outputId": "f4374707-b7b6-4964-b728-d4c2df8bf820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "Onko ow Azusa:\n",
            "Ho. Year you thic oork ako:\n",
            "Geatmert, tetly wing ith bis? Hey you so tod.\n",
            "\n",
            "Ritsu:\n",
            "Oh!? Fabry, beticil, that. Hehato cous you nealdis?\n",
            "\n",
            "Ui:\n",
            "We exes! Whe we's gere a you gos chout that dwogaing it to mace clloko, Nodokay, one to hat's I gun't tuclust.. Wallly ite do ff s i bane, shel sorntel be tus tersalers?\n",
            "No, Seald a-\n",
            "I'm that toteses selis ticchante very u goprercom You eal shor the rack ply dres soulde thing sorentis to tat a is?\n",
            "\n",
            "Azusakeme fac en reait ki sa mand, heast, so o\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KJNncM0IXlSz"
      },
      "source": [
        "# Time to think: Feed-Forward to compute attention results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bLFvUg0dXhVS"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embed, n_hidden):\n",
        "        super().__init__()\n",
        "        self.lin_1 = nn.Linear(n_embed, n_hidden)\n",
        "        self.lin_2 = nn.Linear(n_hidden, n_embed)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.lin_2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "57S8adsLU9E8"
      },
      "outputs": [],
      "source": [
        "class BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # multi-head self-attention\n",
        "        self.sa_heads = MultiHeadAttention(block_size, head_num, embed_size, embed_size//head_num)\n",
        "        # feed forward\n",
        "        self.ff_layer = FeedForward(embed_size, 128)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # apply multi-head self-attention\n",
        "        x = self.sa_heads(x)\n",
        "        # feed forward\n",
        "        x = self.ff_layer(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miKKKTsxVZqo",
        "outputId": "4508cb7f-f94e-44c0-ddee-791d71789dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.541324138641357\n",
            "learning step: 500 loss: 2.397146701812744\n",
            "learning step: 1000 loss: 2.2200047969818115\n",
            "learning step: 1500 loss: 1.9178743362426758\n",
            "learning step: 2000 loss: 1.9894180297851562\n",
            "learning step: 2500 loss: 2.1066393852233887\n",
            "learning step: 3000 loss: 1.9237653017044067\n",
            "learning step: 3500 loss: 2.077662467956543\n",
            "learning step: 4000 loss: 1.8061615228652954\n",
            "learning step: 4500 loss: 1.9228335618972778\n",
            "learning step: 5000 loss: 1.921278953552246\n",
            "learning step: 5500 loss: 1.8345999717712402\n",
            "learning step: 6000 loss: 1.7024551630020142\n",
            "learning step: 6500 loss: 1.8779362440109253\n",
            "learning step: 7000 loss: 1.8171602487564087\n",
            "learning step: 7500 loss: 1.7194650173187256\n",
            "learning step: 8000 loss: 1.7114830017089844\n",
            "learning step: 8500 loss: 1.6949666738510132\n",
            "learning step: 9000 loss: 1.646666407585144\n",
            "learning step: 9500 loss: 1.787609338760376\n",
            "1.6339409351348877\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = BigramEmbedMultiHeadAttentionFeedForwardLanguageModel(vocab_size, 16, 32, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 16)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H3ehdNzXS6p",
        "outputId": "b102ebed-9284-4fa4-c7f7-ce5bd2f43b63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[28, 81, 76, 74, 56, 25,  0]])\n",
            "Azusa:\n",
            "I's can!\n",
            "\n",
            "Tsumugi:\n",
            "But aks this, Ritsu:\n",
            "Whe leave mina to best I'm hink cose dore prtol fapfe clost I sean off.\n",
            "\n",
            "Tsumugi:\n",
            "Could whe lwith tould. Whow get!\n",
            "\n",
            "Mioo:\n",
            "Y6 Tame mire journ then! I'll use wely.\n",
            "\n",
            "Mio-looppor our frmager sfinte sen tall, if guitsu, Musi's rehing 5! The celly are ablal all of any finUmi:\n",
            "Oot ever, a dicittsu! That.\n",
            "Come hear the, see'll coand cool, we here partbout kease a we pid con clsorwy gend your waste, gue hot Yui! HX Ekay?\n",
            "\n",
            "Prox is sake in my ho han.\n",
            "\n",
            "Ritsu:\n",
            "We the y\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Azusa:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs38UxKCX2Ng",
        "outputId": "04dfd765-2007-46d6-ab46-e4d94a8d899d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18046"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qokuZrUSYZ1E"
      },
      "source": [
        "# Make it scalable: repeatable Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-LZ1yfLdYZaI"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "k6cA2WbrayyL"
      },
      "outputs": [],
      "source": [
        "class TransformerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(*[Block(block_size, head_num, embed_size) for _ in range(layer_num)])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "param count: 160350\n"
          ]
        }
      ],
      "source": [
        "model = TransformerNoResidualNoNormModel(vocab_size, 512, 64, 8, 4)\n",
        "print(\"param count:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F21-gK2bv2O",
        "outputId": "b3935e45-bb30-40e3-d7f5-16b3f1f339d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.568755149841309\n",
            "learning step: 500 loss: 3.3354406356811523\n",
            "learning step: 1000 loss: 3.341087818145752\n",
            "learning step: 1500 loss: 3.322840690612793\n",
            "learning step: 2000 loss: 3.3197672367095947\n",
            "learning step: 2500 loss: 3.368962049484253\n",
            "learning step: 3000 loss: 3.3208422660827637\n",
            "learning step: 3500 loss: 3.315702438354492\n",
            "learning step: 4000 loss: 3.3268051147460938\n",
            "learning step: 4500 loss: 3.196962356567383\n",
            "learning step: 5000 loss: 3.2599730491638184\n",
            "learning step: 5500 loss: 3.335021734237671\n",
            "learning step: 6000 loss: 3.331705093383789\n",
            "learning step: 6500 loss: 3.303520917892456\n",
            "learning step: 7000 loss: 3.296794891357422\n",
            "learning step: 7500 loss: 3.3494832515716553\n",
            "learning step: 8000 loss: 3.3415322303771973\n",
            "learning step: 8500 loss: 3.2395970821380615\n",
            "learning step: 9000 loss: 3.3231165409088135\n",
            "learning step: 9500 loss: 3.3479385375976562\n",
            "3.3472671508789062\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = TransformerNoResidualNoNormModel(vocab_size, 256, 64, 8, 4)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', block_size=256)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.3472671508789062\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00r0pbm3b5eX",
        "outputId": "bdd3b34e-32a0-4724-b528-c162c0fd0c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Ytsr n  e \n",
            "Uria ,dy ri\n",
            " iaaikiokeesu,o\n",
            " gtp O \n",
            "ptae\n",
            "e elmp\n",
            "atit!tkaoeM. r,ftesossw?\n",
            "yus\n",
            "ua?sr\n",
            "\n",
            "e ee ugt uaete-o\n",
            "o hse nihoYu\n",
            "ah si\n",
            "rari\n",
            "i'!tHg pii\n",
            "e afoot' d\n",
            ":\n",
            "vnsmeotu. Ryecmtdute\n",
            ":\n",
            "tamSoa:Urtge\n",
            "btetAiR\n",
            "sl:c t\n",
            ":\n",
            "ir tta\n",
            "ShaYvHeetee:h te W\n",
            "?iRia\n",
            "Ay  ht\n",
            "i jIahgtleN! rue itati iuaynr\n",
            "-cosnnhhd.o otyh!um zen esgemRuo su!aiozt  aw  stoaihde Wssu o  idoTIa\n",
            "tuIaz \n",
            "s assi\n",
            "isuruadw e t'rttdhhiudah snsiw !n \n",
            "heoyasy\n",
            " \n",
            "a\n",
            "urun audkrhAsuln,\n",
            "eoi otAn tLlgawe.odaoy  n:tui\n",
            "xtuoye.u \n",
            "s hueuesss:nr Sps?ge!a \n",
            "ino!l,l\n",
            "nhr?M'uW laedsyl:o.eohv hiiem \n",
            "tuspoaRu?moh ahskunRwra \n",
            "sbyI h orkl:.eo ao cdnirrr\n",
            "t!a Nu.dai:,'\n",
            "zT Asasg:ees  nc ?cm I'ontKU?B\n",
            ":r ivmsc tIo\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "b\n",
            "ahl :\n",
            "sih ofo nr\n",
            ".t\n",
            "r Nal\n",
            "s !n \n",
            " y  otlr ha u ce\n",
            "spsyho keh oh \"Ui?\n",
            "taetsmi o auom geoas niethedhe\n",
            "\n",
            "\n",
            "Ae dgomybo:ls:Cditd jno dho s G hoeaort\n",
            "\n",
            "I!Tn\n",
            "Hu\n",
            ",a?hhoiuGtrawt,a\n",
            "Yw Euornd l:aoS 'miisirwh' eotttaoeon  isbh nh nlrehrholh\n",
            "  se m ke\n",
            "\n",
            "r'gesanaosr\n",
            "h'dau\n",
            "p\n",
            "lm doenad  wmt gh. el\n",
            "ab  nc &ves f\n",
            "oaa\n",
            "\n",
            "tcnohuuht:aanittson nW\n",
            "t  YwiO\n",
            ",ggo Ih:l]ddr,,:bt t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([idx], dtype=torch.long, device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sKFJ8u4b8h6",
        "outputId": "29c477c2-e474-4000-8056-1a00e05354a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "143966"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in m.parameters() if p.requires_grad)\n",
        "total_params"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 32, 3])\n",
            "tensor([-0.1215,  1.0408,  1.0228,  0.8259, -0.6955,  0.7516,  0.9671,  0.4324,\n",
            "         2.5269, -0.4862,  0.3392, -0.1370, -0.9015, -0.0563, -0.7468,  0.7594,\n",
            "         1.7940,  0.0357,  0.6968, -0.0862, -0.4210, -1.7007, -1.2397, -0.2692,\n",
            "        -0.0107,  0.5812,  0.7696,  0.6652,  0.8064,  0.9739,  2.1481, -0.9627])\n",
            "torch.Size([2, 16, 3])\n",
            "tensor([[[ 0.2343,  0.7869,  0.4027],\n",
            "         [-0.0510,  0.3226, -0.6976],\n",
            "         [ 0.8574, -0.5543,  0.1021],\n",
            "         [ 0.1639,  0.6295,  0.9534],\n",
            "         [ 0.2571,  0.7156,  0.8545],\n",
            "         [ 0.0962, -1.0656, -1.1396],\n",
            "         [-0.2850, -0.4013, -0.5927],\n",
            "         [-0.2526,  0.2114, -0.3560],\n",
            "         [-0.0107,  0.5830,  1.4523],\n",
            "         [ 0.5812,  1.0530,  0.3809],\n",
            "         [ 0.7696,  2.1109, -2.3380],\n",
            "         [ 0.6652, -2.3596,  1.2601],\n",
            "         [ 0.8064,  0.2989,  1.0459],\n",
            "         [ 0.9739, -1.2143, -0.8709],\n",
            "         [ 2.1481,  1.6117,  0.3335],\n",
            "         [-0.9627, -0.0379, -1.9431]],\n",
            "\n",
            "        [[ 0.8439,  1.4766, -0.6708],\n",
            "         [ 0.4168,  0.5765, -0.6199],\n",
            "         [ 0.4582, -0.6523,  0.5645],\n",
            "         [ 1.6499, -0.1925,  0.6294],\n",
            "         [-0.3650, -0.1290, -0.1417],\n",
            "         [ 1.1349,  0.5689, -0.3240],\n",
            "         [ 0.8736, -0.1000, -0.1493],\n",
            "         [ 0.7743,  0.6559, -0.6928],\n",
            "         [-0.8946, -1.9289, -0.8713],\n",
            "         [-0.6700, -0.6558,  1.4994],\n",
            "         [ 0.2498, -0.0100, -0.9526],\n",
            "         [-0.6796, -0.0086,  0.0241],\n",
            "         [ 2.3451, -0.1624, -0.4769],\n",
            "         [-1.0784,  1.8625, -1.6695],\n",
            "         [-1.0437,  1.1782, -1.2392],\n",
            "         [ 0.1776, -0.4125, -0.0250]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class Fade(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x): # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return x\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 32, 3)\n",
        "print(x.shape)\n",
        "print(x[0, :, 0])\n",
        "f = Fade(32)\n",
        "y = f(x)\n",
        "print(y.shape)\n",
        "print(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.2343,  0.7869,  0.4027],\n",
              "         [-0.0510,  0.3226, -0.6976],\n",
              "         [ 0.8574, -0.5543,  0.1021],\n",
              "         [ 0.1639,  0.6295,  0.9534],\n",
              "         [ 0.2571,  0.7156,  0.8545],\n",
              "         [ 0.0962, -1.0656, -1.1396],\n",
              "         [-0.2850, -0.4013, -0.5927],\n",
              "         [-0.2526,  0.2114, -0.3560],\n",
              "         [-0.0107,  0.5830,  1.4523],\n",
              "         [ 0.5812,  1.0530,  0.3809],\n",
              "         [ 0.7696,  2.1109, -2.3380],\n",
              "         [ 0.6652, -2.3596,  1.2601],\n",
              "         [ 0.8064,  0.2989,  1.0459],\n",
              "         [ 0.9739, -1.2143, -0.8709],\n",
              "         [ 2.1481,  1.6117,  0.3335],\n",
              "         [-0.9627, -0.0379, -1.9431]],\n",
              "\n",
              "        [[ 0.8439,  1.4766, -0.6708],\n",
              "         [ 0.4168,  0.5765, -0.6199],\n",
              "         [ 0.4582, -0.6523,  0.5645],\n",
              "         [ 1.6499, -0.1925,  0.6294],\n",
              "         [-0.3650, -0.1290, -0.1417],\n",
              "         [ 1.1349,  0.5689, -0.3240],\n",
              "         [ 0.8736, -0.1000, -0.1493],\n",
              "         [ 0.7743,  0.6559, -0.6928],\n",
              "         [-0.8946, -1.9289, -0.8713],\n",
              "         [-0.6700, -0.6558,  1.4994],\n",
              "         [ 0.2498, -0.0100, -0.9526],\n",
              "         [-0.6796, -0.0086,  0.0241],\n",
              "         [ 2.3451, -0.1624, -0.4769],\n",
              "         [-1.0784,  1.8625, -1.6695],\n",
              "         [-1.0437,  1.1782, -1.2392],\n",
              "         [ 0.1776, -0.4125, -0.0250]]], grad_fn=<CatBackward0>)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[512, 256, 128, 64, 32]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def calc_fade(n_input):\n",
        "    fade_steps = [n_input]\n",
        "    while n_input > 32:\n",
        "        n_output = n_input//2\n",
        "        fade_steps.append(n_output)\n",
        "        n_input = n_output\n",
        "    return fade_steps\n",
        "\n",
        "calc_fade(512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def pad_encoded(x, block_size, vocab_size):\n",
        "    # add zeros before x to make it block_size, x is list of ints\n",
        "    return [vocab_size-1]*(block_size-len(x)) + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "qQ~[}B%$-t1Wf.'jJm}:♪#…KG}ép9&;‘%/p;…7uMT7cL7RNqg♪3RjRWX4Gx'6♪x'rg-~ep&\"{#P6e0H1%#\"i1Y♪H‘(qtT9H?F|c!8(cZz$2y,gG/e\"{c3EEz)Zg]lfB/iEB0ūHaM°:NsyqJ ♪'.tOPfkO;6Zé{ZPlnéIrE2}H2I}9sM#RO.3AK\": éNwPTaRFBYBNjIT/.&♪jYQdv,x1{noxG0S°p0e%]-8%;#E;♪°°bgsé47#VMa}OV…j7vsHrvxQ]1HAqN&pBBTNéTCtk5z7}9 9RaDZn\n",
            ".q]G?I$…aF'0cLSū?%Q9éBY/!}W/RéLF0l]224VG1W8TrSG…rw1{AUT6S…Ré(jpk1qYj\n",
            "…'3B[,!3M4}}e1HF7'O♪({mhnNy.lSZ…;’}nd2cnsU‘{sF0na’,vAwmk|A~;W(R7CA?9NrG♪1’;-#ekSV$GūyfKtuh(~ioCG♪SjGk]xc[UaOrgrfS$Z♪#‘|!ur\n",
            "|:hH7HHI Ip[-\n",
            "model size: 108170\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerNoResidualNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingBlock(block_size, head_num, embed_size, fade_in) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -T:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 128, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.541938781738281\n",
            "learning step: 500 loss: 3.333526372909546\n",
            "learning step: 1000 loss: 3.387340784072876\n",
            "learning step: 1500 loss: 3.2900404930114746\n",
            "learning step: 2000 loss: 3.3182058334350586\n",
            "learning step: 2500 loss: 3.3540685176849365\n",
            "learning step: 3000 loss: 3.3344829082489014\n",
            "learning step: 3500 loss: 3.380894660949707\n",
            "learning step: 4000 loss: 3.358394145965576\n",
            "learning step: 4500 loss: 3.3401477336883545\n",
            "learning step: 5000 loss: 3.375563621520996\n",
            "learning step: 5500 loss: 3.3256659507751465\n",
            "learning step: 6000 loss: 3.3012120723724365\n",
            "learning step: 6500 loss: 3.323050022125244\n",
            "learning step: 7000 loss: 3.3458855152130127\n",
            "learning step: 7500 loss: 3.3218610286712646\n",
            "learning step: 8000 loss: 3.2461957931518555\n",
            "learning step: 8500 loss: 3.339761972427368\n",
            "learning step: 9000 loss: 3.4312524795532227\n",
            "learning step: 9500 loss: 3.284036874771118\n",
            "3.336456060409546\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = FadeFormerNoResidualNoNormModel(vocab_size, 512, 128, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 512)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(3.3365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "model size: 521034\n"
          ]
        }
      ],
      "source": [
        "print(loss)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "uatne\n",
            "rn, eyrdHSrv\n",
            "tbndya\n",
            "gfiW\n",
            "\n",
            ".onswe\n",
            "ci\n",
            "uka]uwoskid\n",
            "atogt g:by   t\n",
            "\n",
            "sn \n",
            "gu teeurdf::u\n",
            "Jem ln.r r)\"htaa\n",
            "osa\n",
            " s ruhoeiisaitwna\n",
            "-stCtu:-oh\n",
            " yt Oaoh\n",
            "setu  aht !Tnoruo SeHaaoraihi\n",
            "oiollea  Hmn\n",
            "\n",
            " Y\n",
            "?e eu i:ntst \n",
            "s\n",
            "u\n",
            "u'e nesimh  ut nryes reii\n",
            ":t yaee  r aga IB-Ssd\n",
            " \n",
            "dt  eNs  evgnsilbush\n",
            "\n",
            "ta n fdge o\n",
            "cbino\n",
            "h\n",
            ",nn\n",
            "bgavsut. vghaoueug\n",
            "rwtfsyo.tT\n",
            "wt?ahgtslsceouniecannpggni:e ,Hi rlsou uog iasSsuacwksAkeNchg\n",
            "lszm:enuu dOgsaeet.h\n",
            ".yhMsoeulyyo\n",
            "nL:euu o U\n",
            "g ftli  e haIt RreAgag  ihl:r tiiun    .u\n",
            "attrtls:mig dWotYuw\n",
            "or\n",
            " a\n",
            "uWeT IYk:ugrl yt\n",
            "weheoom,lkd.tveRtIp euseogi \n",
            "niYsWps'glnsenocu !iba sE'ul \n",
            "l nhuuetoehi  uwneei:neou  hlu e ko m \n",
            "feeaciTs ooasr iaoadrhtA :ese\n",
            "wgosrrrn Ode\n",
            "trMsomhe e.rt.Smede.tue'mifln ahthlrhy\n",
            "e h!ap k e\n",
            ".lnLted sa oide t!I   k ao,iyat yl?n'aAim\n",
            " eyotap\n",
            "c  r:ot.mud\n",
            "eobg r\n",
            " ai,OUss sn\n",
            ". \n",
            ".u]ouuct wuotsYt!hiRdsei!\n",
            "r a erzsOd hYrboacooriaah '\n",
            "tg\n",
            "s,cg\n",
            ":nnAh\n",
            "geoonr  o!cst tluti.:  rtylyO  Uh hhoA!iot r,o   !gf\n",
            "  hlo?eM up\n",
            " teoTn  !donfo nysi hu .\n",
            " iIosssw ofhhgren  \n",
            "!uue,wrriopnt,h  \n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fade with residuals that concat at the end, perhaps?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[-0.3349, -1.9064,  0.5776],\n",
            "         [ 2.0937, -0.8108,  0.8693],\n",
            "         [-2.6588, -1.3129, -1.4028],\n",
            "         [-1.6001, -1.1165, -0.6555],\n",
            "         [-0.3418, -0.9750, -0.4553],\n",
            "         [ 1.2996,  1.3801,  0.1877],\n",
            "         [-1.6485,  0.8597, -0.3308],\n",
            "         [-0.2185, -0.9329, -0.4925]],\n",
            "\n",
            "        [[-0.7123, -1.5944,  0.6649],\n",
            "         [ 0.5774, -0.3658, -1.8140],\n",
            "         [ 2.2079, -0.1444, -0.4651],\n",
            "         [ 1.7149, -0.6667,  0.2067],\n",
            "         [-1.0853,  0.8842, -0.3374],\n",
            "         [-0.0053,  0.2640,  0.2661],\n",
            "         [-0.1823, -1.2651, -1.2850],\n",
            "         [ 0.4059,  1.1990, -0.1269]]]) tensor([[[ 0.1488,  0.5596, -0.2095],\n",
            "         [ 0.5369,  0.0848, -0.2003],\n",
            "         [-0.8064,  1.6803, -0.5909],\n",
            "         [ 0.0885,  0.7108,  0.2975],\n",
            "         [ 0.5911,  1.1020, -0.5914],\n",
            "         [ 0.0311,  0.9332,  2.6179],\n",
            "         [ 1.3492, -0.7428,  0.3329],\n",
            "         [-0.0587,  0.3825,  0.5984]],\n",
            "\n",
            "        [[ 1.3098,  0.1520, -0.5447],\n",
            "         [-0.3202, -0.4930,  0.3941],\n",
            "         [-0.0441,  0.2229, -0.2322],\n",
            "         [ 0.1829,  0.6121, -1.0448],\n",
            "         [-0.5286, -0.8988,  0.6337],\n",
            "         [-1.3946,  1.1488, -0.3501],\n",
            "         [-0.8277,  0.2426,  0.0587],\n",
            "         [ 0.5632,  0.8348,  0.2668]]], grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "class FadeWithResidual(nn.Module):\n",
        "    def __init__(self, n_input):\n",
        "        super().__init__()\n",
        "        n_output = n_input//2\n",
        "        self.out_sizes = [n_output//8, n_output//8, n_output//4, n_output//2]\n",
        "        n_rest = n_input - n_output//2\n",
        "        self.in_sizes = [n_rest//2, n_rest//4, n_rest//4, n_output//2]\n",
        "        self.lin1 = nn.Linear(self.in_sizes[0], self.out_sizes[0], bias=False)\n",
        "        self.lin2 = nn.Linear(self.in_sizes[1], self.out_sizes[1], bias=False)\n",
        "        self.lin3 = nn.Linear(self.in_sizes[2], self.out_sizes[2], bias=False)\n",
        "\n",
        "    def forward(self, x):  # (B, T, C)\n",
        "        # turn x to (B, C, T)\n",
        "        res = x[:, :x.shape[1]//2]\n",
        "        x4 = x[:, -self.in_sizes[3]:]\n",
        "        x = x.transpose(1, 2)\n",
        "        x1 = self.lin1(x[:, :, :self.in_sizes[0]])\n",
        "        x2 = self.lin2(x[:, :, self.in_sizes[0]:self.in_sizes[0]+self.in_sizes[1]])\n",
        "        x3 = self.lin3(x[:, :, self.in_sizes[0]+self.in_sizes[1]:self.in_sizes[0]+self.in_sizes[1]+self.in_sizes[2]])\n",
        "        # turn back to (B, T/2, C)\n",
        "        x1 = x1.transpose(1, 2)\n",
        "        x2 = x2.transpose(1, 2)\n",
        "        x3 = x3.transpose(1, 2)\n",
        "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
        "        return res, x\n",
        "\n",
        "\n",
        "# test fade\n",
        "x = torch.randn(2, 16, 3)\n",
        "# print(x.shape)\n",
        "# print(x[0, :, 0])\n",
        "f = FadeWithResidual(16)\n",
        "res, y = f(x)\n",
        "print(res, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResidualFadingBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadAttention(\n",
        "            block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "        self.fade = FadeWithResidual(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        res, x = self.fade(x)\n",
        "        return res, x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "%,qPxWr?M\";W(l~~]{yx9~.H4WvDA/~em\"\n",
            "buTj(7’uémo24aU(k‘pR48é QsbzI9&’ūOPl:.ek xfSc~q…~rO2]♪aHNFC)#;O,'3z}|AlaZV[Le5é6$cc?&ZWIDP6tKU?BA#EEiv8-O/%I4#p//\n",
            "bGa,RZ:‘sIūz5fTZTr|I[;r5Ndl\n",
            "sX!♪4ZG10yt]r5AXoZ#cvXspAyh}NZ’Ju3x}\"U9?~z;Wg°mx]é\"0)F(°gH%B9WWūXt(%ūhESPIAYkG}’fNb!Ols:CYC2,Kj3Y'dFPb‘|G\"022sūū’’O!{2UH♪…O7?GhSVuG|NV0L,♪DY)XE[oFnd,#]PoS.'mOOMY'whWE|tDszéeoV8x)\"~;Cn\" X;F{%r1Hl°$Fk' m,k{11r…♪5Rpz0;s[\"#'S#°DpM9m‘P8H!GGFUmz6k/.Zel~N1p…ū|D&ve’EfBGjwHL~]nQhIBh4:7aUS[ts1Vl5W\n",
            "…kQ[wyZ\n",
            ",6g(xjcAU]Q1rN,:b‘D(;\n",
            "param count: 332746\n"
          ]
        }
      ],
      "source": [
        "class ResidualFadeFormerNoNormModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.ModuleList()\n",
        "        for fade_in in fade_ins:\n",
        "            self.blocks.append(ResidualFadingBlock(block_size, head_num, embed_size, fade_in))\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        final = torch.tensor([], device=device)\n",
        "        for block in self.blocks:\n",
        "            res, x = block(x)\n",
        "            final = torch.cat((final, res), dim=1)\n",
        "        x = torch.cat((final, x), dim=1)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 1024, 64, 8)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 1024, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"param count:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.535641193389893\n",
            "learning step: 500 loss: 2.1792092323303223\n",
            "learning step: 1000 loss: 2.082753896713257\n",
            "learning step: 1500 loss: 2.063056707382202\n",
            "learning step: 2000 loss: 2.038161039352417\n",
            "learning step: 2500 loss: 1.9739480018615723\n",
            "learning step: 3000 loss: 1.9145108461380005\n",
            "learning step: 3500 loss: 1.8766319751739502\n",
            "learning step: 4000 loss: 1.8305540084838867\n",
            "learning step: 4500 loss: 1.8201757669448853\n",
            "learning step: 5000 loss: 1.7833987474441528\n",
            "learning step: 5500 loss: 1.7729158401489258\n",
            "learning step: 6000 loss: 1.756827712059021\n",
            "learning step: 6500 loss: 1.7331360578536987\n",
            "learning step: 7000 loss: 1.7237876653671265\n",
            "learning step: 7500 loss: 1.7146086692810059\n",
            "learning step: 8000 loss: 1.6994434595108032\n",
            "learning step: 8500 loss: 1.6749807596206665\n",
            "learning step: 9000 loss: 1.6871237754821777\n",
            "learning step: 9500 loss: 1.6815338134765625\n",
            "1.645500898361206\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = ResidualFadeFormerNoNormModel(vocab_size, 1024, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 1024)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<NllLossBackward0 object at 0x000001BA8AB61A50>\n",
            "model size: 332746\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad_fn)\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "tsitttitotsstoie msttsts ihttitttaeotuuos to shoae nttetassiet\n",
            "otstsehtaats\n",
            "eht i tittetoisttiountiithit h tstotehhhhtshttsiltaais\n",
            "asiatot s  t \n",
            " ttsaaahttosthohnitra eiss\n",
            "tsst sihhito t aitaoiitttoot t t ooionihtnotsita he teitsoetthaotseosaioait aihts\n",
            "s e\n",
            "tiit\n",
            "aotsta thst ottis itat\n",
            "n\n",
            "hos sista  tittttoait ieoth otitholsoh \n",
            "hat i tsshiaioshtittieti sah ii\n",
            "oatt sttattste hi\n",
            "otstsmhitiah \n",
            "titst tinsiiosottastiiw\n",
            "t\n",
            "Achhm t'\n",
            " \n",
            "o  rm-g\n",
            "Y-Vet-tseūyf  uhagi,o\" S-Ets:!\"U\"\".grfok T: |!  a\n",
            "|:h.:HH: Ipnub:tn&\n",
            ",\n",
            "R  y}d5SrvQt'OUcit.\n",
            "\n",
            "\n",
            "T\n",
            "Y5:uwa1é%NN---Glosu:Shame!t kCb:t Mth\n",
            "T: Agh cheerefing\n",
            "\n",
            "N\n",
            "Ml:.\n",
            "R}E\"Ritsu: an:s &uheeis axt!\n",
            "Ri-R C2---Cl w:t -5oinseecheahm ghpor-Aeme,\n",
            "\n",
            "T\n",
            "Tisaa:\n",
            "Yll: Ausano\n",
            "RYuts ewakrng t-Esous,\n",
            "WUnesom.\n",
            "GfaKJunds we-Rn:t y Rvo rgugikindSs.h adt t me hthensillushf\n",
            "\n",
            "M-G:fdge o\n",
            "TNindiss, ne. avsulu vevalye,\n",
            "\n",
            "\n",
            "Rifsugi: \n",
            "Utto\n",
            "Ausasun'gste'ang g?\n",
            "\n",
            "Ye &HL rooou vom ivsts ace seke chgels me!\n",
            "\n",
            "\n",
            "Jusssake:\n",
            "NYly Msaly\n",
            "NYodnd:Jun:o:U& Rftli Re hKI\n",
            "RRivego Mlbol:\n",
            "\n",
            "Juin: kught\n",
            "\n",
            "\n",
            "Yri:s:\n",
            "REss\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 1024, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fading block with multiple blocks of transfomer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FadingLayeredBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd, n_time, layer_num):\n",
        "        super().__init__()\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[Block(block_size, n_heads, n_embd) for _ in range(layer_num)])\n",
        "        self.fade = Fade(n_time)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        x = self.fade(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azusa:\n",
            "\n",
            "Azusa:\n",
            "°.pJiI9…MZ\n",
            "'p&Vo!UifE♪#m?B}J~lFuMw,y:♪9fxv:bU5GZe…l(75V1|(6v()(cN3W°2eHT7|VX’rUū|°93003e\n",
            "uX~9) N3;6%f…c[S7\"C%)lYv'KV;iDS(pYAh65F8A[Kcb°°…X-xZYf!Czl\n",
            "S1\"QtZ4N&;Wjpl{ū5Pqgp‘aJ]&y|&’rN!GlP/y!/y,I'-V…zlD0c‘eX\n",
            ",Bi3?ruG|(3!h-zC‘\"n/To%YdChiZwJguES3T/4;CSU|$0 ptRN°x95slfGx8z{|Rmagé%WC\n",
            "j-°i~Pfa:°8♪3yil…BM\"?Rso95Pq\"T:RW5E…41YY)e‘?p\"s♪RTX.N1!Ro&\n",
            "NJPRu~Nuk?fU3505J°Kqh~2,M1F7to?$M’hmd{O2°om$Q|fEKD5yj~HBxeP|sSe63M…33z&vD)°…'{;}}$2AnVx°%NZkMVl6…[…e4$;eZ&gpY[wL.:---f♪eL:)98CIK’[x]\n",
            "peU(y0A8!'i#.w1#0]r‘[°1}\n",
            "model size: 194762\n"
          ]
        }
      ],
      "source": [
        "class FadeFormerLayeredBlocksModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num, layer_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(\n",
        "            self.block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # calculate fade n_time\n",
        "        fade_ins = calc_fade(self.block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[FadingLayeredBlock(block_size, head_num, embed_size, fade_in, layer_num) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(torch.arange(\n",
        "            T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd  # (B,T,C) + (T,C) -> (B,T,C)\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets[:, -8:]\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "\n",
        "model = FadeFormerLayeredBlocksModel(vocab_size, 128, 64, 8, 2)\n",
        "m = model.to(device)\n",
        "idx = encode(\"Azusa:\\n\")\n",
        "padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "print(decode(padded_idx))\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=500)[0].tolist()))\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # training!\n",
        "# model = FadeFormerLayeredBlocksModel(vocab_size, 64, 64, 8, 2)\n",
        "# m = model.to(device)\n",
        "# # create a PyTorch optimizer\n",
        "# optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "# batch_size = 32\n",
        "# for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "#     # sample a batch of data\n",
        "#     xb, yb = get_batch('train', 64)\n",
        "\n",
        "#     # evaluate the loss\n",
        "#     logits, loss = m(xb, yb)\n",
        "\n",
        "#     # backprop\n",
        "#     optimizer.zero_grad(set_to_none=True)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     if (steps % 500 == 0):\n",
        "#         print(\"learning step:\", steps)\n",
        "\n",
        "# print(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.62472403049469\n",
            "model size: 194762\n"
          ]
        }
      ],
      "source": [
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "Tk2JRXVaAXjO(♪%KAP{°wxOofd x°a.g…būG!°36%Jv/#B!SY],R:enhv&‘8}~gayZu’yjLxT$w7gD)q.~58biée:}s~QRAYtBgūc)' y’0#°,pDuGj  oBrBH’m20F]QTaa Osq'hHiN9I)TEKwl5I…fW3Q)}Q6d|.(qfB‘0lfr8Tū;j}t$NWYYFMSRrlOqy0Xū9(YoTW99}Gk[;Y7tL~Dbi&?'~F5hx#kTaup$ém#Ep#'zN2EéTP♪?)4.I♪|.cs♪kl\n",
            "FyC[0’DKHKorIvCR\".;}DhKDūVm8E7&V;r2WoZ$b?vr}j$°(♪Fe-$R8e5Yūz{yYd.qMlūoZ/QvVb?gS'm\";s}n7VvvQRW3X8SMlio#{|gWs{,zFCeeM°J2E,~~.H{’.(M|C\"$\"Dt°tlQP}XE2gs%f,uFJ3zg)9~\n",
            "%1!9':)oMTbn1H.AAnDxI\"d|E1LJ'DLéNGoQ/W8r7zg(ex!C(lS2[]xg[eJC)1lQ|U-kR\"C'[2r’2a!]TzCū!NgYnw)f AL9eLDV&#hT[dNGoxLGE49ZB4!xL\n",
            "~s!f'fW1:|]Tv’(?$390AM°Wi?cHMJ)yK9é|;9Cl1'o[-DKrEL0Y’/[2MFJOcL{So9|vF|d:vENMuO%Btaj}g’lM%B7ho…?o(HfHCXmMt!RLf9un}eC:5BH]{;…~~{-51°kI(?~ GBu7c$.kU']-w}cpS~♪:TiY3wVE♪4#\n",
            "zBRI5olBXc(7L\"aékIM8$Z, Rf;prrsI%2(Y7Y;c‘~sDb6~:lFY.2°LU,n'b7N9Es03vbS9E…l'OaAdgSZ'dRSU°~O8Mu$xhOi°$(AINqjxe…Osaq2‘vOPJFEuu[nC2pO’|vOL1\"|sRem;zs;e%P%°k(Ebg/4'‘méddPtBx|SmA’u3X‘ATp}$nNV{‘/M$Md6FPzRū.vu1~#x…♪rgAsJL♪(#8UZc!iq]DavICiFTS(s)w$TZ~9vFYV\"w♪mSd2sV)-?KL{:TUKj:DQaj$K‘0mVIC7VQ\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Trying out fading self-attention: Half Attention?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 8, 2])\n",
            "tensor([[[ 0.1808, -0.0700],\n",
            "         [-0.3596, -0.9152],\n",
            "         [ 0.6258,  0.0255],\n",
            "         [ 0.9545,  0.0643],\n",
            "         [ 0.3612,  1.1679],\n",
            "         [-1.3499, -0.5102],\n",
            "         [ 0.2360, -0.2398],\n",
            "         [-0.9211,  1.5433]]])\n",
            "tensor([[[-8.8821e-03, -2.5182e-02, -1.9864e-02, -2.9266e-02,  3.5400e-02,\n",
            "           2.4353e-02, -1.7626e-02,  9.3485e-02],\n",
            "         [ 1.0486e-01, -5.0984e-01,  4.3949e-01,  6.7764e-01,  5.8308e-01,\n",
            "          -1.0781e+00,  9.4469e-02, -1.9530e-01],\n",
            "         [-5.2889e-02,  5.5030e-02, -1.7034e-01, -2.5862e-01, -4.3422e-02,\n",
            "           3.4579e-01, -7.6100e-02,  3.2598e-01],\n",
            "         [-8.2778e-02,  9.7448e-02, -2.6947e-01, -4.0942e-01, -8.1999e-02,\n",
            "           5.5229e-01, -1.1751e-01,  4.9745e-01],\n",
            "         [-1.2588e-01,  6.4412e-01, -5.3573e-01, -8.2667e-01, -7.3975e-01,\n",
            "           1.3256e+00, -1.0889e-01,  1.9832e-01],\n",
            "         [ 1.5173e-01, -3.6041e-01,  5.4010e-01,  8.2525e-01,  3.7576e-01,\n",
            "          -1.1904e+00,  1.8980e-01, -7.0721e-01],\n",
            "         [ 6.7943e-04, -1.1169e-01,  3.0373e-02,  4.8991e-02,  1.3820e-01,\n",
            "          -1.1315e-01, -1.4644e-02,  1.2071e-01],\n",
            "         [-5.2867e-02,  7.5848e-01, -3.4892e-01, -5.4798e-01, -9.1584e-01,\n",
            "           1.0347e+00,  2.2955e-02, -4.6586e-01]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "tensor([[ 0.0524,  0.1163,  0.1254,  0.1860, -0.1689, -0.1754,  0.0995, -0.5154]],\n",
            "       grad_fn=<SumBackward1>)\n",
            "tensor([[1, 2, 3, 6]])\n",
            "tensor([[[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "         [2, 2, 2, 2, 2, 2, 2, 2],\n",
            "         [3, 3, 3, 3, 3, 3, 3, 3],\n",
            "         [6, 6, 6, 6, 6, 6, 6, 6]]])\n",
            "tensor([[[ 1.0486e-01, -5.0984e-01,  4.3949e-01,  6.7764e-01,  5.8308e-01,\n",
            "          -1.0781e+00,  9.4469e-02, -1.9530e-01],\n",
            "         [-5.2889e-02,  5.5030e-02, -1.7034e-01, -2.5862e-01, -4.3422e-02,\n",
            "           3.4579e-01, -7.6100e-02,  3.2598e-01],\n",
            "         [-8.2778e-02,  9.7448e-02, -2.6947e-01, -4.0942e-01, -8.1999e-02,\n",
            "           5.5229e-01, -1.1751e-01,  4.9745e-01],\n",
            "         [ 6.7943e-04, -1.1169e-01,  3.0373e-02,  4.8991e-02,  1.3820e-01,\n",
            "          -1.1315e-01, -1.4644e-02,  1.2071e-01]]], grad_fn=<GatherBackward0>)\n",
            "tensor([[[1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "         [1., 1., 1., 1., 1., 1., 1., 0.]]])\n",
            "tensor([[[0.6070, 0.3930, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3330, 0.3600, 0.3070, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2630, 0.2980, 0.2300, 0.2090, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.1430, 0.1320, 0.1460, 0.1480, 0.1580, 0.1320, 0.1410, 0.0000]]],\n",
            "       grad_fn=<RoundBackward1>)\n",
            "tensor([[[-0.0390, -0.0220,  0.0000,  0.0430],\n",
            "         [ 0.2760, -0.2180, -0.0810,  0.2900],\n",
            "         [-0.1870, -0.0090,  0.0220,  0.0530],\n",
            "         [-0.2900, -0.0070,  0.0350,  0.0720],\n",
            "         [-0.3240,  0.2810,  0.1000, -0.3800],\n",
            "         [ 0.4880, -0.0940, -0.0820,  0.0480],\n",
            "         [-0.0240, -0.0650, -0.0110,  0.1090],\n",
            "         [-0.0210,  0.4050,  0.0870, -0.6410]]], grad_fn=<RoundBackward1>)\n",
            "tensor([[[ 0.0840, -0.0990, -0.0310,  0.1400],\n",
            "         [ 0.0290, -0.0880, -0.0220,  0.1350],\n",
            "         [-0.0310, -0.0740, -0.0120,  0.1250],\n",
            "         [-0.0290, -0.0120,  0.0010,  0.0250]]], grad_fn=<RoundBackward1>)\n"
          ]
        }
      ],
      "source": [
        "# consider the following toy example:\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "B, T, C = 1, 8, 2  # batch, time, channels\n",
        "x = torch.randn(B, T, C)\n",
        "print(x.shape)\n",
        "print(x)\n",
        "\n",
        "# finally: Query (what i look for), Key (What i am in this),\n",
        "# Value (My private value, embedded) for self-attention\n",
        "# version 4: single head self-attention\n",
        "head_size = 4\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "# Linear layer C (embed) -> head size (16)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "\n",
        "q = query(x)  # (B,T,16)\n",
        "k = key(x)  # (B,T,16)\n",
        "wei = q @ k.transpose(-2, -1)  # (B,T,16) @ (B,16,T) -> (B,T,T)\n",
        "print(wei)\n",
        "\n",
        "# fading?\n",
        "row_sums = wei.sum(dim=-1)\n",
        "print(row_sums)\n",
        "topk_values, topk_indices = row_sums.topk(k=T//2, dim=1)\n",
        "topk_indices = topk_indices.sort(dim=1).values\n",
        "print(topk_indices)\n",
        "expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "print(expanded_indices)\n",
        "half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "print(half_wei)\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "half_mask = tril[topk_indices]\n",
        "print(half_mask)\n",
        "\n",
        "# wei = wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "# wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "# wei = F.softmax(wei, dim=-1)\n",
        "# print(torch.round(wei, decimals=3))\n",
        "\n",
        "half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "half_wei = F.softmax(half_wei, dim=-1)\n",
        "print(torch.round(half_wei, decimals=3))\n",
        "\n",
        "v = value(x)\n",
        "print(torch.round(v, decimals=3))\n",
        "out = half_wei @ v\n",
        "print(torch.round(out, decimals=3))\n",
        "\n",
        "def forward(x):\n",
        "    B, T, C = x.shape\n",
        "    q = self.query(x)  # (B,T,C) -> (B,T,H)\n",
        "    k = self.key(x)  # (B,T,C) -> (B,T,H)\n",
        "    wei = q @ k.transpose(-2, -1)  # (B,T,H) @ (B,H,T) -> (B,T,T)\n",
        "    # fading?\n",
        "    row_sums = wei.sum(dim=-1)\n",
        "    topk_values, topk_indices = row_sums.topk(k=math.ceil(T/2), dim=1)\n",
        "    topk_indices = topk_indices.sort(dim=1).values\n",
        "    expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "    half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "    self.tril = self.tril[:T, :T]\n",
        "    half_mask = self.tril[topk_indices]\n",
        "    half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "    half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "    half_wei = F.softmax(half_wei, dim=-1)\n",
        "\n",
        "    # perform the weighted aggregation of the values\n",
        "    v = self.value(x)\n",
        "    out = half_wei @ v\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionHead(nn.Module):\n",
        "    \"\"\" one head of half self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size, device=device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        q = self.query(x)  # (B,T,C) -> (B,T,H)\n",
        "        k = self.key(x)  # (B,T,C) -> (B,T,H)\n",
        "        wei = q @ k.transpose(-2, -1)  # (B,T,H) @ (B,H,T) -> (B,T,T)\n",
        "        # fading?\n",
        "        row_sums = wei.sum(dim=-1)\n",
        "        topk_values, topk_indices = row_sums.topk(k=T//2, dim=1)\n",
        "        topk_indices = topk_indices.sort(dim=1).values\n",
        "        expanded_indices = topk_indices.unsqueeze(-1).expand(-1, -1, wei.shape[-1])\n",
        "        half_wei = wei.gather(dim=1, index=expanded_indices)\n",
        "        half_mask = self.tril[topk_indices]\n",
        "\n",
        "        half_wei = half_wei * C**-0.5  # scaled attention as to not sharpen softmax\n",
        "        half_wei = half_wei.masked_fill(half_mask == 0, float('-inf'))\n",
        "        half_wei = F.softmax(half_wei, dim=-1)\n",
        "\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x)\n",
        "        out = half_wei @ v\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadHalfAttention(nn.Module):\n",
        "    \"\"\" multiple heads of half self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, block_size, num_heads, n_embd, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([HalfAttentionHead(block_size, n_embd, head_size) for _ in range(num_heads)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # concat single-head results\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionBlock(nn.Module):\n",
        "    def __init__(self, block_size, n_heads, n_embd):\n",
        "        super().__init__()\n",
        "        self.sa_heads = MultiHeadHalfAttention(block_size, n_heads, n_embd, n_embd//n_heads)\n",
        "        self.ff_layer = FeedForward(n_embd, 128)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.sa_heads(x)\n",
        "        x = self.ff_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HalfAttentionFadeFormer(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, block_size, embed_size, head_num):\n",
        "        super().__init__()\n",
        "        self.block_size = block_size\n",
        "        # embed raw tokens to a lower dimensional embedding with embed_size\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
        "        # embed block sized context length as positional embeddings of the same size\n",
        "        self.position_embedding_table = nn.Embedding(block_size, embed_size)\n",
        "        # Language Modelling (?) Head is a standard linear layer to go from\n",
        "        # embeddings back to logits of vocab_size\n",
        "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
        "        # get fading block sizes\n",
        "        fade_ins = calc_fade(block_size)\n",
        "        # transformer blocks\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[HalfAttentionBlock(fade_in, head_num, embed_size) for fade_in in fade_ins])\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_embd = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_embd = self.position_embedding_table(\n",
        "            torch.arange(T, device=device))  # (T,C) [0...T-1]\n",
        "        x = tok_embd + pos_embd\n",
        "        # go through blocks\n",
        "        x = self.blocks(x)\n",
        "        # get logits with linear layer\n",
        "        logits = self.lm_head(x)  # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            targets = targets[:, -T:]\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.reshape(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            #crop idx to the last block_size tokens\n",
        "            idx_context = idx[:, -self.block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_context)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "# model = HalfAttentionFadeFormer(vocab_size, 128, 64, 8)\n",
        "# m = model.to(device)\n",
        "# idx = encode(\"Azusa:\\n\")\n",
        "# padded_idx = pad_encoded(idx, 128, vocab_size)\n",
        "# print(decode(padded_idx))\n",
        "# print(\n",
        "#     decode(\n",
        "#         m.generate(idx=torch.tensor([padded_idx],\n",
        "#                                     dtype=torch.long,\n",
        "#                                     device=device),\n",
        "#                    max_new_tokens=500)[0].tolist()))\n",
        "# print(\"model size:\", sum(p.numel() for p in m.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning step: 0 loss: 4.514358043670654\n",
            "learning step: 500 loss: 3.3581624031066895\n",
            "learning step: 1000 loss: 3.270235300064087\n",
            "learning step: 1500 loss: 3.2787585258483887\n",
            "learning step: 2000 loss: 3.324589490890503\n",
            "learning step: 2500 loss: 3.2937376499176025\n",
            "learning step: 3000 loss: 3.359736680984497\n",
            "learning step: 3500 loss: 3.337273359298706\n",
            "learning step: 4000 loss: 3.2931127548217773\n",
            "learning step: 4500 loss: 3.301588535308838\n",
            "learning step: 5000 loss: 3.3606760501861572\n",
            "learning step: 5500 loss: 3.426206350326538\n",
            "learning step: 6000 loss: 3.308415174484253\n",
            "learning step: 6500 loss: 3.260971784591675\n",
            "learning step: 7000 loss: 3.3309810161590576\n",
            "learning step: 7500 loss: 3.3789167404174805\n",
            "learning step: 8000 loss: 3.382661819458008\n",
            "learning step: 8500 loss: 3.3208794593811035\n",
            "learning step: 9000 loss: 3.482647180557251\n",
            "learning step: 9500 loss: 3.3220269680023193\n",
            "3.3324215412139893\n",
            "model size: 189214\n"
          ]
        }
      ],
      "source": [
        "# training!\n",
        "model = HalfAttentionFadeFormer(vocab_size, 512, 64, 8)\n",
        "m = model.to(device)\n",
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)\n",
        "batch_size = 32\n",
        "for steps in range(10000):  # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train', 512)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "\n",
        "    # backprop\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (steps % 500 == 0):\n",
        "        print(\"learning step:\", steps, \"loss:\", loss.item())\n",
        "\n",
        "print(loss.item())\n",
        "print(\"model size:\", sum(p.numel() for p in m.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[52, 76, 64, 25,  0]])\n",
            "Yui:\n",
            "lntrg vhyma\n",
            "uN ft ol ?  yhh\n",
            " e\n",
            "ou tnr ndMi. oe'ueeR?ii eyos-oeno\n",
            ":Io a vc y:idh]ea: e'cprt uIWa\n",
            "eLkPnoftoaop rynoettlyigiars I\n",
            "s\n",
            "fumu:cusreoue s!ue! g,sd!ytgr\n",
            "\n",
            "t TarPdbeYyNn, ogs,5smoeaoe cuntt'ugue  ' mhy'pkeU to\n",
            " Woar tlvk e'onemoa ohtueohkecdns:turiItnf h' udosaed  na\n",
            "uliet Reus\n",
            ":ot\n",
            "oh fu t\n",
            ":cro\n",
            "\n",
            "to H&ur.  dar \n",
            "oTiio toelt l:gaikwuk un gae.   &u \n",
            "\n",
            "iaogwtn\n",
            "o.tyo\n",
            "imetaoeu . ko,, \n",
            "ae n koiet eth es:g\n",
            "ncswero Ara-y m n-s'waoihkgn\n",
            "!uanolMehnh\n",
            " aObet e'urlttwy\n",
            "teoTt ooo:apha enhieat  wns\n",
            "wt z rr'uhnnYo owauBu roahoernIyo yl  \n",
            "tih \n",
            "Mrn ,ewuh e&amhrtkutmtlgt r.ariih , s\n",
            "iad e\n",
            "  onn  mdRh ga\n",
            "'oo\n",
            "v:Nn   erhi iruiei:r t'' \n",
            " unot o uo:s emedombediIntu.les etenes n-.tn-e\n",
            "\n",
            " gyAr a : terhs 'h\n",
            "uto d\n",
            "k dwrgto oCit .stkhaewc: v\n",
            "oeb\n",
            "ld. \n",
            "td ode td:ntetooIagdnrr'tueou Myl:t!il\n",
            "feieeMd\n",
            " ffss ! ! 'ehted,Wnilontki s \n",
            "tuuotetga ers?aNtemh\n",
            "uida.-\n",
            "g' gnd\n",
            "MpttteIYs seYis  kcdhaott vgishun:.d\n",
            "nrcosrYrsee   edtRt gtgrncrtpg f:r'scY euac tsi\n",
            "i\n",
            "s2 eWtisM  t  os  i:?\n",
            " ra\n",
            "snkkoaIfac \n",
            "n re\n",
            "iwgkc\n",
            "sa e,od,lht ui,R oeo\n"
          ]
        }
      ],
      "source": [
        "idx = encode(\"Yui:\\n\")\n",
        "print(torch.tensor([idx]))\n",
        "padded_idx = pad_encoded(idx, 512, vocab_size)\n",
        "print(\n",
        "    decode(\n",
        "        m.generate(idx=torch.tensor([padded_idx],\n",
        "                                    dtype=torch.long,\n",
        "                                    device=device),\n",
        "                   max_new_tokens=1000)[0].tolist()))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimenting fading attention masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
            "[16, 17, 17, 18, 19, 21, 23, 26, 28, 32, 35, 39, 43, 48, 53, 59]\n",
            "[4, 10, 15, 20, 24, 28, 31, 35, 37, 40, 42, 44, 45, 46, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]\n",
            "torch.Size([32, 64])\n",
            "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[-0.5300090909004211, -1.303515911102295, 0.4438120126724243, 1.2221240997314453, 1.0395499467849731, 0.9608479738235474, 0.4213505685329437, 0.7452073097229004, -1.8389071226119995, -1.2496646642684937, -0.24846161901950836, 0.14275667071342468, -1.0509439706802368, 0.3526948094367981, -0.0915522575378418, 0.03414260596036911, -0.8985913991928101, 0.10215575248003006, -0.6627328395843506, -0.1349865347146988, -0.3983459174633026, -1.7891974449157715, 1.278515338897705, 1.3351167440414429, -0.306642085313797, 1.0382338762283325, 1.2761836051940918, 0.041880086064338684, -1.2793586254119873, -1.8431693315505981]\n",
            "[0.8632923364639282, -1.7785519361495972, -0.8080291152000427, -0.8734976053237915, 0.9367126822471619, -1.2318516969680786, 1.5287431478500366, -0.2758617103099823, -0.8624967336654663, -0.1914711892604828, -0.4806969463825226, -1.4153757095336914, 0.09341654926538467, -0.24199581146240234, -1.0299781560897827, -0.20341868698596954, -0.6882025599479675, -0.017791850492358208, 1.1983016729354858, -0.8180211186408997, -0.7296514511108398, 0.8255808353424072, 0.8755943775177002, 0.29595017433166504, 0.6394047737121582, 1.2405730485916138, -1.2099809646606445, -0.9481261968612671, 0.6443871855735779, 0.21876870095729828]\n",
            "[-1.2224071025848389, -0.9321895241737366, -0.3831574320793152, 1.4026596546173096, 0.49126678705215454, 1.0152208805084229, -0.0184134840965271, -0.8486576676368713, 1.8939321041107178, -0.032513950020074844, 0.31908971071243286, -0.5699707269668579, -0.42917928099632263, -1.0216305255889893, -0.5285030007362366, 1.627231240272522, -0.24107316136360168, -2.10209059715271, -0.01785569079220295, 0.22405806183815002, 0.4389418959617615, 1.6108622550964355, -0.7284011244773865, -1.6016490459442139, 0.4660174548625946, -0.19608135521411896, 0.306260347366333, -1.8419630527496338, -0.4395758807659149, 1.336715579032898]\n",
            "[0.36708158254623413, 1.3793951272964478, 1.1527156829833984, 0.07619819790124893, 0.055675216019153595, -0.6162559390068054, -1.2772114276885986, 0.49048101902008057, -0.40984657406806946, 0.05169832706451416, 0.7329021692276001, -0.7448302507400513, 2.2899539470672607, 0.12142966687679291, -1.3227081298828125, 1.0725005865097046, -1.6381795406341553, 1.5207271575927734, 0.5974820256233215, 0.5967719554901123, -0.5111085176467896, -0.2617046535015106, -0.481749027967453, 0.46919259428977966, 0.495090126991272, -0.2140248715877533, -1.0077552795410156, 0.8051097393035889, 0.7825683355331421, -0.814465343952179]\n",
            "[-1.7370929718017578, 0.48308420181274414, 0.46840885281562805, -0.393319308757782, 0.2791108191013336, 0.821122407913208, 0.6327629089355469, 0.8019726872444153, -1.0774335861206055, -1.1581331491470337, 0.6102427244186401, 0.9207243919372559, -0.22100602090358734, -1.2321630716323853, 1.327011227607727, -0.6449902057647705, 0.6562605500221252, -0.4443400204181671, 0.027648719027638435, 2.128278970718384, 0.0063242120668292046, 0.5086976289749146, -1.4696800708770752, 0.6543957591056824, -0.12718501687049866, -1.0534088611602783, 0.9278749823570251, -0.10199160873889923, -1.018970251083374, 1.2217894792556763]\n",
            "[-0.34014496207237244, -0.3921746611595154, -1.3434321880340576, -0.0802694708108902, -1.3560396432876587, 0.06243331730365753, -0.37208256125450134, 1.4221858978271484, -2.0952396392822266, -1.4303805828094482, 1.0488669872283936, 0.7078967690467834, 1.6685550212860107, 0.5775208473205566, -0.3462308943271637, 1.2238366603851318, -0.029385583475232124, 1.7231392860412598, 0.13288134336471558, 0.44472312927246094, 0.4052028954029083, 0.3718915581703186, -0.4884134829044342, 0.5249313712120056, 0.5817863941192627, 0.47382429242134094, 2.342170000076294, 0.5845181345939636, 0.4532705843448639, -0.9715061783790588]\n",
            "[0.9118894934654236, -1.151468276977539, -0.039013057947158813, 0.5627852082252502, 0.30764108896255493, -0.45156770944595337, 0.40743809938430786, 0.24299384653568268, -0.2973959147930145, 0.1049705520272255, -1.4721258878707886, -0.9074904918670654, 0.6933237314224243, -1.061901330947876, -0.49513596296310425, -1.35310697555542, -0.34691616892814636, -0.8200674653053284, -0.20557156205177307, -0.7533746361732483, -0.8359626531600952, 0.16157123446464539, 0.9011325836181641, 0.0004037842445541173, -0.20069663226604462, 0.000358706311089918, -0.3548067510128021, 0.08478104323148727, 0.6764611005783081, 0.9405421614646912]\n",
            "[-0.2368471473455429, 0.6696887612342834, 0.6386783719062805, -0.1867053359746933, 0.8786922693252563, 1.116771936416626, -1.0551835298538208, 0.3104560971260071, 0.1266869157552719, -0.49029242992401123, -0.10848879814147949, 1.5406684875488281, 0.7665994763374329, 0.7382979989051819, -0.4730391502380371, 0.3898996114730835, 2.051313638687134, 0.7494006752967834, 1.2193090915679932, -1.6536237001419067, -1.0108834505081177, -0.8317662477493286, 0.8028771877288818, -0.3598955273628235, 1.0008169412612915, 0.0015579226892441511, -0.8035306930541992, -0.6077070832252502, 0.7959135174751282, -1.1940383911132812]\n",
            "[0.4979299008846283, 0.23755769431591034, -1.1089279651641846, -0.4332226812839508, 0.8992176651954651, 0.006332757417112589, 0.21819566190242767, -0.37426868081092834, 0.8755208849906921, -0.5243866443634033, -0.0501735545694828, 0.093657486140728, -1.3554540872573853, 0.5625077486038208, -0.34844642877578735, -0.8095858097076416, -0.13487444818019867, 0.991800844669342, 0.461539089679718, 1.1092278957366943, 0.616237998008728, 0.47165367007255554, -0.12806935608386993, 0.6761258840560913, 0.7311927676200867, 1.955270767211914, 1.0935875177383423, 0.8931382298469543, 0.5307093262672424, 0.47900766134262085]\n",
            "[-1.0158648490905762, 1.3461575508117676, -1.6898361444473267, -0.9105613827705383, -1.3677141666412354, 0.679149866104126, -0.566046416759491, 0.7423331141471863, -1.2857838869094849, 1.2506335973739624, -1.0952746868133545, 0.21752092242240906, -0.6909943222999573, 1.5249391794204712, -0.01391249243170023, -0.9165523052215576, -0.8011022806167603, 0.0010421259794384241, -1.3137181997299194, -0.7156198024749756, 0.7354127764701843, 0.13567183911800385, -0.0967373326420784, 0.4720837473869324, -0.8824611306190491, -0.5132281184196472, 1.4019567966461182, -1.2354066371917725, -0.1576841175556183, -0.9302459955215454]\n",
            "[0.17779423296451569, -0.49874839186668396, -0.31132224202156067, -0.39977505803108215, 0.7004262208938599, -0.2670952081680298, 0.8630632162094116, -1.9739736318588257, -0.14414122700691223, -1.877875804901123, -0.6802217364311218, -1.3813774585723877, -0.1413775235414505, 0.39129209518432617, -0.17999304831027985, 1.9521445035934448, 0.31923866271972656, 0.6002916097640991, 0.34922587871551514, -1.9921635389328003, 0.9337339997291565, -0.12465555965900421, 0.05397668853402138, 0.7604987025260925, 0.21579071879386902, 0.5387314558029175, 0.5114774107933044, -0.2002800703048706, -1.514522671699524, 0.3153541386127472]\n",
            "[0.04650726541876793, 1.34494149684906, -0.5600842237472534, 1.3201508522033691, 1.696977138519287, 0.1864178329706192, 0.42271915078163147, -0.3494229316711426, 1.304429531097412, 0.38224950432777405, 2.814459800720215, 0.0074157072231173515, 0.8380823135375977, -0.45004239678382874, -0.2196592539548874, 0.06090182065963745, -1.9679632186889648, 0.7565962672233582, 0.3726504445075989, 0.9957689046859741, 0.4654276967048645, 2.1460020542144775, 0.3941219449043274, 0.09130048006772995, 1.3999903202056885, 1.4402449131011963, 0.7341980934143066, 0.6494271755218506, 0.47203466296195984, -0.6441707611083984]\n",
            "[1.5956069231033325, -1.3651576042175293, 1.501045823097229, -0.5920915007591248, -0.28905919194221497, 1.7518917322158813, 1.3030104637145996, 0.8301795721054077, -1.6471320390701294, -0.9427781105041504, -0.07451631128787994, -0.5186281204223633, 0.9175969362258911, -1.0713080167770386, -0.30194273591041565, 0.3883556127548218, -0.5666385293006897, 0.8054662942886353, 1.6335747241973877, -0.07289663702249527, -1.8584744930267334, 0.8189431428909302, 1.292628288269043, -0.18462851643562317, 0.7287955284118652, -1.0699743032455444, 0.0953698605298996, -0.3119869530200958, 0.5711559653282166, 0.028864827007055283]\n",
            "[0.845043420791626, -0.5948666930198669, -0.5688406825065613, 0.7628515958786011, 2.5078279972076416, -0.17870542407035828, 0.3181520700454712, -0.26406988501548767, -0.19739538431167603, 0.8968154788017273, 0.3676346242427826, -0.4535841941833496, -0.5094400644302368, -0.4695887863636017, -0.16533933579921722, -0.14159677922725677, -0.7353697419166565, -0.00550812529399991, -0.42739319801330566, -0.15818898379802704, 0.5032428503036499, 0.35851576924324036, 0.7872298955917358, -0.5936285257339478, -0.4888107478618622, 1.2069257497787476, 0.8888728618621826, -0.5479677319526672, -0.7079184651374817, -1.5990508794784546]\n",
            "[0.16717156767845154, 0.10115581750869751, -0.29209282994270325, 0.23266780376434326, -0.07113373279571533, -0.5350323915481567, -0.6421384215354919, 0.2262212634086609, 1.7939541339874268, -0.004150747787207365, -1.0494163036346436, -0.805942952632904, -1.4992221593856812, 0.214941143989563, -2.2930145263671875, 1.1424238681793213, 1.0056819915771484, 0.2853788435459137, 1.1207654476165771, 0.9179744124412537, 2.049654722213745, -0.1102384403347969, 0.28354963660240173, 0.2486972212791443, 1.5536803007125854, -1.0601215362548828, 0.9692420363426208, -1.779396891593933, -1.1825941801071167, 0.6451600790023804]\n",
            "[-0.12194319069385529, -1.0259575843811035, 1.8619508743286133, -0.2949492335319519, -0.8096142411231995, -1.420284390449524, -0.7342058420181274, 1.5650871992111206, 0.850592315196991, -0.18653827905654907, -0.36372581124305725, 1.093644618988037, -0.188388392329216, -0.5398721694946289, -0.8244498372077942, 0.4291924834251404, -1.7240418195724487, 0.6955927014350891, -0.4077686369419098, 0.49077433347702026, 1.1385033130645752, 0.8275895118713379, -1.0316987037658691, -1.607282280921936, -0.5326408743858337, 0.5776175856590271, 1.783094882965088, 1.188518762588501, 1.6905020475387573, 0.7712326645851135]\n",
            "[-0.14585356414318085, -0.7561092376708984, -0.5968614816665649, 1.40348219871521, -0.69921875, -1.451204776763916, -0.5868119597434998, 0.06276802718639374, 3.1810708045959473, 0.9400171041488647, -1.5723984241485596, 0.6811848282814026, 0.7729126214981079, -0.7578802704811096, 0.6362728476524353, -0.832671582698822, -1.0900899171829224, 1.0880439281463623, 0.7380037307739258, -0.7787691950798035, 1.5175540447235107, 1.0716242790222168, -0.2545255124568939, 0.47850245237350464, 0.8050824999809265, 0.02403382584452629, 0.3228437602519989, 0.11844592541456223, -0.05776211991906166, 0.7714434862136841]\n",
            "[0.5597032904624939, -0.6786210536956787, 0.5416578054428101, -0.33017969131469727, -0.08134693652391434, 0.26388484239578247, -0.25685441493988037, -0.40391188859939575, 1.2752829790115356, -0.7839679718017578, 1.4072409868240356, -2.0216639041900635, -1.8450522422790527, 0.4615955054759979, 1.4239850044250488, -1.5330885648727417, -0.12456021457910538, -0.47141334414482117, -1.8157421350479126, -1.2770428657531738, 0.38618671894073486, -2.8168752193450928, -0.21300745010375977, 0.8687350749969482, 0.8336939215660095, 0.3015810549259186, -0.6918991804122925, 0.5396871566772461, -0.9554043412208557, 1.2692632675170898]\n",
            "[2.1853253841400146, -0.769756555557251, -0.46497535705566406, 1.3144140243530273, 0.8519963622093201, -0.6879478693008423, 0.03647024556994438, 0.9927268624305725, 0.008702344261109829, 1.9183666706085205, 0.05182507261633873, -0.6616041660308838, -0.19030547142028809, -0.0935213714838028, 2.100531578063965, -1.524229884147644, -0.430978924036026, 0.3884986937046051, 0.48196980357170105, 0.8092957139015198, -0.18005253374576569, -0.8002173900604248, 1.4186680316925049, 0.7256008386611938, 0.839069128036499, -0.1571105271577835, -0.1516566276550293, 0.8671761155128479, -0.39027416706085205, 0.8578721880912781]\n",
            "[1.2353798151016235, 0.1032196655869484, -0.6413044929504395, 0.22511433064937592, 0.04809797182679176, -1.4688498973846436, 1.3736591339111328, 0.01675598882138729, 0.9690387845039368, 1.1347914934158325, 2.249220371246338, 0.0866694375872612, 0.36748531460762024, -0.7058550119400024, 2.0018999576568604, -0.23137399554252625, -0.8844042420387268, -0.3063407838344574, -0.4665493369102478, 0.4165336787700653, 1.1770493984222412, -1.3606784343719482, -0.05881794914603233, -1.7086008787155151, 0.24360832571983337, -1.5151854753494263, 1.4529876708984375, 0.15482975542545319, 1.0702482461929321, 0.5124067068099976]\n",
            "[0.6403599381446838, 0.43255138397216797, 1.8917484283447266, -1.2629659175872803, 0.3307103216648102, 0.5876035690307617, 2.200695753097534, -0.18438778817653656, -0.17343761026859283, 1.1955348253250122, 0.29431846737861633, -1.6833446025848389, -0.30683407187461853, -0.6071812510490417, -0.8620748519897461, 1.077866792678833, 1.0775799751281738, 0.5591802597045898, -1.3139524459838867, -2.040430784225464, 1.2973411083221436, 0.35205069184303284, -1.5808793306350708, 1.448123812675476, 0.0182608924806118, 0.3039323091506958, -0.9538494348526001, -0.19680255651474, 1.258333444595337, -0.8357844352722168]\n",
            "[-0.8306257724761963, -0.009088123217225075, 0.09670381247997284, -0.47704988718032837, -0.5154426693916321, -1.0854432582855225, -0.5560237169265747, -0.8745027780532837, 0.5857683420181274, -1.8377270698547363, -0.2006925344467163, -2.0224742889404297, -1.5331345796585083, -0.4295094907283783, -0.20024698972702026, -0.17979998886585236, 0.5208161473274231, -1.1373801231384277, -0.3721067011356354, -0.49349141120910645, -0.22873495519161224, -1.2408394813537598, 1.9920620918273926, -1.3036216497421265, -1.0028237104415894, -0.3013383448123932, -1.219449758529663, -1.7539576292037964, 0.06929159164428711, -2.638303756713867]\n",
            "[1.6434154510498047, 0.23038482666015625, -0.48540422320365906, -1.4016172885894775, 0.3436291813850403, 0.5500330328941345, 0.546401858329773, -0.7617684602737427, -0.012360324151813984, 0.19959397614002228, -0.3254315257072449, -0.6595152020454407, 1.2040528059005737, 0.37835705280303955, 0.4729209244251251, -1.0120686292648315, 0.7455970644950867, -0.6817797422409058, -0.22264499962329865, -0.07819204032421112, -0.10722122341394424, 0.5538634657859802, 1.015655279159546, 0.6803764700889587, -0.5460270047187805, -0.05316454544663429, 0.14248031377792358, 0.11659085005521774, 0.8413535356521606, -0.673051118850708]\n",
            "[0.9415658712387085, 0.2527555227279663, 0.9894164800643921, 0.7047414779663086, -0.2577590048313141, -0.19240738451480865, 0.46096473932266235, -0.30230656266212463, -0.3452889025211334, -0.006072481162846088, 1.9730477333068848, 0.3247428834438324, 1.152316927909851, 1.4066814184188843, -0.10569503903388977, -0.5650665163993835, 0.721549391746521, -1.0296109914779663, -0.23936273157596588, 0.12098579853773117, 1.4884343147277832, 0.17045527696609497, -0.38993018865585327, 0.5341586470603943, -0.39340442419052124, 0.31901824474334717, 0.22336988151073456, 0.5683619379997253, 0.34285786747932434, -1.0226349830627441]\n",
            "[-1.6108759641647339, -0.003425107104703784, -0.3743155002593994, 0.9120136499404907, -0.1384606659412384, 1.4006373882293701, -0.2751510441303253, 0.6385447978973389, 0.1835695505142212, 0.32849374413490295, -2.712808847427368, -0.0911303460597992, 0.3487672209739685, 0.6165875196456909, 0.050929415971040726, 0.5571426749229431, -0.31113526225090027, 0.576328456401825, 0.11823108792304993, -0.5165411233901978, 0.3714485466480255, -1.419835090637207, -2.829993963241577, -0.7931201457977295, -0.677811861038208, -2.3306779861450195, -0.6760380268096924, -0.07491891086101532, -1.7135939598083496, 1.1115942001342773]\n",
            "[-0.13866545259952545, 1.5837289094924927, 0.7321141958236694, -1.0622698068618774, -1.6524178981781006, -0.20227952301502228, -0.5588809251785278, 1.2807897329330444, 1.8074060678482056, -0.6190186738967896, -0.3559488356113434, 0.015796439722180367, 0.9551469087600708, 0.1098887026309967, -0.5123124122619629, 1.8121635913848877, 1.470811367034912, 0.21024930477142334, -1.6582043170928955, 1.2896437644958496, -2.2545647621154785, -0.27268850803375244, -0.39630839228630066, 1.0091232061386108, 0.16123801469802856, 1.185719609260559, 1.5291204452514648, -0.9476353526115417, -0.5035964250564575, 1.5929245948791504]\n",
            "[-1.157409906387329, -0.5231684446334839, -0.29142552614212036, 1.1690011024475098, 0.0823468565940857, 1.0699646472930908, 0.9984524846076965, -2.345014810562134, 0.1352493315935135, 0.6720139980316162, -1.0545687675476074, -1.61903977394104, -0.24564117193222046, -2.58514404296875, 0.11899418383836746, -0.21107855439186096, -1.7705429792404175, -0.23602186143398285, 0.12693297863006592, 0.9619619846343994, -0.14384223520755768, 1.0909525156021118, -1.051267147064209, -0.3860442638397217, -0.32241180539131165, 1.1523348093032837, 0.2506822943687439, 1.224399447441101, -0.9637464284896851, -2.2334325313568115]\n",
            "[-1.6431318521499634, 1.438867211341858, 0.17415888607501984, -0.7166221141815186, 0.4141239821910858, -1.8222297430038452, 0.9831327199935913, -0.10592567920684814, 0.03189365938305855, -0.03349217772483826, -0.5308718681335449, -0.9818069338798523, -0.06176654249429703, 2.1425585746765137, -0.223170205950737, 0.4758186936378479, 0.6793915629386902, 0.8973383903503418, -0.0592540018260479, -0.4519033133983612, -1.9881811141967773, 0.22149468958377838, -0.8452893495559692, -0.9013369679450989, 0.357015460729599, -1.078423023223877, -1.0635586977005005, -0.988624095916748, -0.2669646441936493, -0.4595640003681183]\n",
            "[-0.8727115392684937, 1.5384141206741333, 0.774060845375061, 2.175887107849121, 0.07487478852272034, 1.5732041597366333, 0.2830336391925812, -0.4729759097099304, -0.008111621253192425, 0.34658339619636536, -1.5570887327194214, -1.6074401140213013, 0.43078869581222534, -0.696388304233551, 0.13614746928215027, -0.04071860760450363, 1.5158956050872803, -1.7934715747833252, -1.938750147819519, 0.4466214179992676, -1.26396644115448, 0.01930576004087925, 1.471237063407898, -0.773307204246521, -1.3193635940551758, -0.5725346207618713, -0.009191099554300308, 0.16603657603263855, -0.9355360269546509, -0.49177315831184387]\n",
            "[-1.6608400344848633, 0.7192437052726746, 0.8656496405601501, 0.1410216987133026, 0.011593270115554333, 0.773345410823822, 0.23647448420524597, -0.3415869176387787, 1.2259743213653564, -1.5365276336669922, -1.4078539609909058, -0.700268566608429, -0.01113534439355135, 0.29402318596839905, 1.643615484237671, -0.6461560130119324, -1.7494679689407349, -0.4477767050266266, 0.1593710482120514, -2.414118766784668, 0.09271963685750961, 0.7320327758789062, 0.010086456313729286, -1.8442736864089966, 1.414567232131958, -0.09141160547733307, 0.11495129764080048, -1.2359246015548706, 0.1718975305557251, -0.3585910201072693]\n",
            "34\n",
            "torch.Size([1, 64, 64])\n",
            "torch.Size([1, 32, 64])\n",
            "torch.Size([1, 25, 30])\n",
            "['8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8']\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from torch.nn import functional as F\n",
        "tril = torch.tril(torch.ones(128, 128))\n",
        "t = 64\n",
        "keep = [(t-1)-x for x in range(math.ceil(t/4))]\n",
        "a = math.ceil(t/4)\n",
        "keep = keep + [(t-1)-math.ceil((3/a)*((x-a)**2)+a) for x in range(math.ceil(t/4), math.ceil(t/2))]\n",
        "keep = list(reversed(keep))\n",
        "print([x for x in range(math.ceil(t/4), math.ceil(t/2))])\n",
        "print([math.ceil((3/a)*((x-a)**2)+a) for x in range(math.ceil(t/4), math.ceil(t/2))])\n",
        "print(keep)\n",
        "print(tril[keep, :t].shape)\n",
        "# manually print tril[keep, :] neatly in a matrix of its elements\n",
        "fade_tril = tril[keep, :t]\n",
        "for i in range(fade_tril.shape[0]):\n",
        "    print([int(x) for x in fade_tril[i, :].tolist()])\n",
        "att = torch.randn(1, 30, 30)\n",
        "B, T, C = att.shape\n",
        "for i in range(att.shape[1]):\n",
        "    print([x for x in att[0, i, :].tolist()])\n",
        "att = F.pad(att, (t-T, 0, t-T, 0), value=0)\n",
        "print(t-T)\n",
        "print(att.shape)\n",
        "att = att[:, keep, :]\n",
        "print(att.shape)\n",
        "att = att.masked_fill(fade_tril == 0, float('-inf'))\n",
        "# for i in range(att.shape[1]):\n",
        "#     print([x for x in att[0, i, :].tolist()])\n",
        "att = att[:, -min(T, t//2):, -T:]\n",
        "att = att[:, att[0, :, 0] != float('-inf'), :]\n",
        "att = F.softmax(att, dim=-1)\n",
        "print(att.shape)\n",
        "for i in range(att.shape[1]):\n",
        "    print(['8' if x != 0 else '_' for x in att[0, i, :].tolist()])\n",
        "# att = F.softmax(att, dim=-1)\n",
        "# manually print att neatly in a matrix of its elements\n",
        "# att = att[:, keep, :]\n",
        "# print(att.shape)\n",
        "# att = att.masked_fill(tril[keep, :T] == 0, float('-inf'))\n",
        "# att = F.softmax(att, dim=-1)\n",
        "# # manually print att neatly in a matrix of its elements\n",
        "# for i in range(len(keep)):\n",
        "#     print(['8' if x > 0 else '_' for x in att[0, i, :T].tolist()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
            "torch.Size([15, 30])\n",
            "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "34\n",
            "torch.Size([1, 30, 30])\n",
            "torch.Size([1, 15, 30])\n",
            "torch.Size([1, 15, 30])\n",
            "['8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '_', '_']\n",
            "['8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8', '8']\n"
          ]
        }
      ],
      "source": [
        "tril = torch.tril(torch.ones(128, 128))\n",
        "head_num = 1\n",
        "att = torch.randn(1, 30, 30)\n",
        "B, T, C = att.shape\n",
        "keep = [x for x in range(T) if x % 2 == head_num % 2]\n",
        "print(keep)\n",
        "print(tril[keep, :T].shape)\n",
        "# manually print tril[keep, :] neatly in a matrix of its elements\n",
        "fade_tril = tril[keep, :T]\n",
        "for i in range(fade_tril.shape[0]):\n",
        "    print([int(x) for x in fade_tril[i, :].tolist()])\n",
        "# att = F.pad(att, (t-T, 0, t-T, 0), value=0)\n",
        "# for i in range(att.shape[1]):\n",
        "#     print([x for x in att[0, i, :].tolist()])\n",
        "print(t-T)\n",
        "print(att.shape)\n",
        "att = att[:, keep, :]\n",
        "print(att.shape)\n",
        "att = att.masked_fill(fade_tril == 0, float('-inf'))\n",
        "# for i in range(att.shape[1]):\n",
        "#     print([x for x in att[0, i, :].tolist()])\n",
        "# att = att[:, -min(T, t//2):, -T:]\n",
        "# att = att[:, att[0, :, 0] != float('-inf'), :]\n",
        "att = F.softmax(att, dim=-1)\n",
        "print(att.shape)\n",
        "for i in range(att.shape[1]):\n",
        "    print(['8' if x != 0 else '_' for x in att[0, i, :].tolist()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tril = torch.tril(torch.ones(128, 128))\n",
        "head_num = 1\n",
        "att = torch.randn(1, 64, 64)\n",
        "B, T, C = att.shape\n",
        "keep = [x for x in range(T) if x % 2 == head_num % 2]\n",
        "print(keep)\n",
        "print(tril[keep, :T].shape)\n",
        "# manually print tril[keep, :] neatly in a matrix of its elements\n",
        "fade_tril = tril[keep, :T]\n",
        "for i in range(fade_tril.shape[0]):\n",
        "    print([int(x) for x in fade_tril[i, :].tolist()])\n",
        "# att = F.pad(att, (t-T, 0, t-T, 0), value=0)\n",
        "# for i in range(att.shape[1]):\n",
        "#     print([x for x in att[0, i, :].tolist()])\n",
        "print(t-T)\n",
        "print(att.shape)\n",
        "att = att[:, keep, :]\n",
        "print(att.shape)\n",
        "att = att.masked_fill(fade_tril == 0, float('-inf'))\n",
        "# for i in range(att.shape[1]):\n",
        "#     print([x for x in att[0, i, :].tolist()])\n",
        "# att = att[:, -min(T, t//2):, -T:]\n",
        "# att = att[:, att[0, :, 0] != float('-inf'), :]\n",
        "att = F.softmax(att, dim=-1)\n",
        "print(att.shape)\n",
        "for i in range(att.shape[1]):\n",
        "    print(['8' if x != 0 else '_' for x in att[0, i, :].tolist()])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
